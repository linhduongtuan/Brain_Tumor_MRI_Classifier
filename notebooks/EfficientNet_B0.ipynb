{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40178,
     "status": "ok",
     "timestamp": 1588213047201,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "rPwL9bdoBNzQ",
    "outputId": "553f83f0-cbf1-48d5-a184-4f4c8ff055ac"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PIL\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "#from pytorch_metric_learning import loss\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from timm.models.layers.activations import *\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from randaugment import RandAugment, ImageNetPolicy, Cutout\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179460,
     "status": "ok",
     "timestamp": 1588213186502,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "584ea32f-dbe1-4465-8e60-e0f4e5c96a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Glioma', 'Meningioma', 'No_Tumor', 'Pituitary']\n",
      "{'train': 2870, 'val': 394}\n",
      "cuda:1\n",
      "{0: 'Glioma', 1: 'Meningioma', 2: 'No_Tumor', 3: 'Pituitary'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 224, 224])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/home/linh/Downloads/Brain/'\n",
    "\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        ImageNetPolicy(),\n",
    "        Cutout(size=16),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "batch_size = 100\n",
    "data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4, pin_memory = True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)\n",
    "print(dataset_sizes)\n",
    "print(device)\n",
    "\n",
    "### we get the class_to_index in the data_Set but what we really need is the cat_to_names  so we will create\n",
    "_ = image_datasets['train'].class_to_idx\n",
    "cat_to_name = {_[i]: i for i in list(_.keys())}\n",
    "print(cat_to_name)\n",
    "    \n",
    "# Run this to test the data loader\n",
    "images, labels = next(iter(data_loader['val']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226470,
     "status": "ok",
     "timestamp": 1588213233519,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "N350JAHpu8c3",
    "outputId": "96a2d095-f78f-4ca5-eb0c-c5390e367831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def showimage(data_loader, number_images, cat_to_name):\\n    dataiter = iter(data_loader)\\n    images, labels = dataiter.next()\\n    images = images.numpy() # convert images to numpy for display\\n    # plot the images in the batch, along with the corresponding labels\\n    fig = plt.figure(figsize=(number_images, 4))\\n    for idx in np.arange(number_images):\\n        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\\n        img = np.transpose(images[idx])\\n        plt.imshow(img)\\n        ax.set_title(cat_to_name[labels.tolist()[idx]])\\n        \\n#### to show some  images\\nshowimage(data_loader['test'], 20, cat_to_name)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def showimage(data_loader, number_images, cat_to_name):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.numpy() # convert images to numpy for display\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(number_images, 4))\n",
    "    for idx in np.arange(number_images):\n",
    "        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\n",
    "        img = np.transpose(images[idx])\n",
    "        plt.imshow(img)\n",
    "        ax.set_title(cat_to_name[labels.tolist()[idx]])\n",
    "        \n",
    "#### to show some  images\n",
    "showimage(data_loader['test'], 20, cat_to_name)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226461,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "L9jdFtBjSAE6",
    "outputId": "f0f393c5-4369-422c-9aef-fc290ccc941d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = models.resnet50(pretrained=True)\n",
    "#model = timm.create_model('resnet50', pretrained=True)\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "#model.fc #show fully connected layer for ResNet family\n",
    "model.classifier #show the classifier layer (fully connected layer) for EfficientNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226454,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "6beb0600-5fdf-4ae6-a216-40c32a13bb9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters of the model is: 7919520\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# define `classifier` for ResNet\n",
    "# Otherwise, define `fc` for EfficientNet family \n",
    "#because the definition of the full connection/classifier of 2 CNN families is differnt\n",
    "fc = nn.Sequential(OrderedDict([#('fc1', nn.Linear(1280, 1000, bias=True)),\n",
    "                                 ('fc1', nn.Linear(2048, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, 4)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "# connect base model (EfficientNet_B0) with modified classifier layer\n",
    "model.fc = fc\n",
    "#criterion = LabelSmoothingCrossEntropy()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Nadam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.01,momentum=0.9,\n",
    "                      nesterov=True,\n",
    "                      weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "#lr = lambda x: (((1 + math.cos(x * math.pi / num_epochs)) / 2) ** 1) * 0.9\n",
    "#scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr)\n",
    "#show our model architechture and send to GPU\n",
    "model.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(\"The number of parameters of the model is:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPNx-TodPpVA"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=200, checkpoint = None):\n",
    "    since = time.time()\n",
    "\n",
    "    if checkpoint is None:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = math.inf\n",
    "        best_acc = 0.\n",
    "    else:\n",
    "        print(f'Val loss: {checkpoint[\"best_val_loss\"]}, Val accuracy: {checkpoint[\"best_val_accuracy\"]}')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "   \n",
    "    # Tensorboard summary\n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch +1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(data_loader[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if i % 1000 == 999:\n",
    "                    print('[%d, %d] loss: %.8f' % \n",
    "                          (epoch + 1, i, running_loss / (i * inputs.size(0))))\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':                \n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.8f} Acc: {:.8f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # Record training loss and accuracy for each phase\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Train/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            else:\n",
    "                writer.add_scalar('Valid/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Valid/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            # deep copy the model\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                print(f'New best model found!')\n",
    "                print(f'New record ACC: {epoch_acc}, previous record acc: {best_acc}')\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'best_val_loss': best_loss,\n",
    "                            'best_val_accuracy': best_acc,\n",
    "                            'scheduler_state_dict' : scheduler.state_dict(),\n",
    "                            }, \n",
    "                            CHECK_POINT_PATH\n",
    "                            )\n",
    "                print(f'New record acc is SAVED: {epoch_acc}')\n",
    "\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.8f} Best val loss: {:.8f}'.format(best_acc, best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vcXkJFOlP4NJ",
    "outputId": "e47fadb8-c292-4051-8a56-bbdc5868abe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint not found\n",
      "Epoch 1/300\n",
      "----------\n",
      "train Loss: 2.87063046 Acc: 0.42926829\n",
      "val Loss: 1.51380117 Acc: 0.53045685\n",
      "New best model found!\n",
      "New record ACC: 0.5304568527918782, previous record acc: 0.0\n",
      "New record acc is SAVED: 0.5304568527918782\n",
      "\n",
      "Epoch 2/300\n",
      "----------\n",
      "train Loss: 0.67243277 Acc: 0.75191638\n",
      "val Loss: 1.01420908 Acc: 0.66243655\n",
      "New best model found!\n",
      "New record ACC: 0.6624365482233502, previous record acc: 0.5304568527918782\n",
      "New record acc is SAVED: 0.6624365482233502\n",
      "\n",
      "Epoch 3/300\n",
      "----------\n",
      "train Loss: 0.53935499 Acc: 0.78954704\n",
      "val Loss: 0.89407872 Acc: 0.73857868\n",
      "New best model found!\n",
      "New record ACC: 0.7385786802030456, previous record acc: 0.6624365482233502\n",
      "New record acc is SAVED: 0.7385786802030456\n",
      "\n",
      "Epoch 4/300\n",
      "----------\n",
      "train Loss: 0.49558660 Acc: 0.80940767\n",
      "val Loss: 0.95696784 Acc: 0.72335025\n",
      "\n",
      "Epoch 5/300\n",
      "----------\n",
      "train Loss: 0.42879629 Acc: 0.83101045\n",
      "val Loss: 0.96580727 Acc: 0.74873096\n",
      "New best model found!\n",
      "New record ACC: 0.748730964467005, previous record acc: 0.7385786802030456\n",
      "New record acc is SAVED: 0.748730964467005\n",
      "\n",
      "Epoch 6/300\n",
      "----------\n",
      "train Loss: 0.36817817 Acc: 0.86306620\n",
      "val Loss: 0.84288340 Acc: 0.81218274\n",
      "New best model found!\n",
      "New record ACC: 0.8121827411167513, previous record acc: 0.748730964467005\n",
      "New record acc is SAVED: 0.8121827411167513\n",
      "\n",
      "Epoch 7/300\n",
      "----------\n",
      "train Loss: 0.33876725 Acc: 0.87630662\n",
      "val Loss: 0.76169890 Acc: 0.80710660\n",
      "\n",
      "Epoch 8/300\n",
      "----------\n",
      "train Loss: 0.30477558 Acc: 0.87526132\n",
      "val Loss: 0.79454555 Acc: 0.82741117\n",
      "New best model found!\n",
      "New record ACC: 0.8274111675126903, previous record acc: 0.8121827411167513\n",
      "New record acc is SAVED: 0.8274111675126903\n",
      "\n",
      "Epoch 9/300\n",
      "----------\n",
      "train Loss: 0.29244510 Acc: 0.89094077\n",
      "val Loss: 0.84346086 Acc: 0.82487310\n",
      "\n",
      "Epoch 10/300\n",
      "----------\n",
      "train Loss: 0.29355674 Acc: 0.88745645\n",
      "val Loss: 0.77467116 Acc: 0.82487310\n",
      "\n",
      "Epoch 11/300\n",
      "----------\n",
      "train Loss: 0.28480093 Acc: 0.89233449\n",
      "val Loss: 0.78802100 Acc: 0.82741117\n",
      "\n",
      "Epoch 12/300\n",
      "----------\n",
      "train Loss: 0.26948961 Acc: 0.89442509\n",
      "val Loss: 0.76938430 Acc: 0.81725888\n",
      "\n",
      "Epoch 13/300\n",
      "----------\n",
      "train Loss: 0.23761984 Acc: 0.90801394\n",
      "val Loss: 0.71292276 Acc: 0.84263959\n",
      "New best model found!\n",
      "New record ACC: 0.8426395939086294, previous record acc: 0.8274111675126903\n",
      "New record acc is SAVED: 0.8426395939086294\n",
      "\n",
      "Epoch 14/300\n",
      "----------\n",
      "train Loss: 0.23648042 Acc: 0.91463415\n",
      "val Loss: 0.84811981 Acc: 0.82487310\n",
      "\n",
      "Epoch 15/300\n",
      "----------\n",
      "train Loss: 0.23444787 Acc: 0.90452962\n",
      "val Loss: 0.77742679 Acc: 0.84263959\n",
      "\n",
      "Epoch 16/300\n",
      "----------\n",
      "train Loss: 0.23210337 Acc: 0.91498258\n",
      "val Loss: 0.68459383 Acc: 0.86548223\n",
      "New best model found!\n",
      "New record ACC: 0.8654822335025381, previous record acc: 0.8426395939086294\n",
      "New record acc is SAVED: 0.8654822335025381\n",
      "\n",
      "Epoch 17/300\n",
      "----------\n",
      "train Loss: 0.22146264 Acc: 0.91289199\n",
      "val Loss: 0.72195645 Acc: 0.87309645\n",
      "New best model found!\n",
      "New record ACC: 0.8730964467005076, previous record acc: 0.8654822335025381\n",
      "New record acc is SAVED: 0.8730964467005076\n",
      "\n",
      "Epoch 18/300\n",
      "----------\n",
      "train Loss: 0.20060915 Acc: 0.92473868\n",
      "val Loss: 0.79895110 Acc: 0.83502538\n",
      "\n",
      "Epoch 19/300\n",
      "----------\n",
      "train Loss: 0.21420388 Acc: 0.91846690\n",
      "val Loss: 1.01296045 Acc: 0.80456853\n",
      "\n",
      "Epoch 20/300\n",
      "----------\n",
      "train Loss: 0.19392787 Acc: 0.92613240\n",
      "val Loss: 0.77556143 Acc: 0.85279188\n",
      "\n",
      "Epoch 21/300\n",
      "----------\n",
      "train Loss: 0.19504384 Acc: 0.92682927\n",
      "val Loss: 0.80114446 Acc: 0.85279188\n",
      "\n",
      "Epoch 22/300\n",
      "----------\n",
      "train Loss: 0.19453569 Acc: 0.92369338\n",
      "val Loss: 0.98975403 Acc: 0.81472081\n",
      "\n",
      "Epoch 23/300\n",
      "----------\n",
      "train Loss: 0.19142494 Acc: 0.92891986\n",
      "val Loss: 0.85616558 Acc: 0.82233503\n",
      "\n",
      "Epoch 24/300\n",
      "----------\n",
      "train Loss: 0.17731812 Acc: 0.93205575\n",
      "val Loss: 0.98430124 Acc: 0.80456853\n",
      "\n",
      "Epoch 25/300\n",
      "----------\n",
      "train Loss: 0.16995656 Acc: 0.93763066\n",
      "val Loss: 0.75490648 Acc: 0.86548223\n",
      "\n",
      "Epoch 26/300\n",
      "----------\n",
      "train Loss: 0.18847322 Acc: 0.92578397\n",
      "val Loss: 0.86621733 Acc: 0.81725888\n",
      "\n",
      "Epoch 27/300\n",
      "----------\n",
      "train Loss: 0.18387890 Acc: 0.93728223\n",
      "val Loss: 0.96384261 Acc: 0.80964467\n",
      "\n",
      "Epoch 28/300\n",
      "----------\n",
      "train Loss: 0.17303942 Acc: 0.93310105\n",
      "val Loss: 0.83549998 Acc: 0.83756345\n",
      "\n",
      "Epoch 29/300\n",
      "----------\n",
      "train Loss: 0.16195853 Acc: 0.93763066\n",
      "val Loss: 0.82385860 Acc: 0.85279188\n",
      "\n",
      "Epoch 30/300\n",
      "----------\n",
      "train Loss: 0.16686570 Acc: 0.93414634\n",
      "val Loss: 0.93486869 Acc: 0.81979695\n",
      "\n",
      "Epoch 31/300\n",
      "----------\n",
      "train Loss: 0.15527770 Acc: 0.94076655\n",
      "val Loss: 0.97017037 Acc: 0.82487310\n",
      "\n",
      "Epoch 32/300\n",
      "----------\n",
      "train Loss: 0.16035583 Acc: 0.93867596\n",
      "val Loss: 0.89410441 Acc: 0.83248731\n",
      "\n",
      "Epoch 33/300\n",
      "----------\n",
      "train Loss: 0.16777061 Acc: 0.93554007\n",
      "val Loss: 0.72437258 Acc: 0.85786802\n",
      "\n",
      "Epoch 34/300\n",
      "----------\n",
      "train Loss: 0.13942036 Acc: 0.94634146\n",
      "val Loss: 0.76824217 Acc: 0.85786802\n",
      "\n",
      "Epoch 35/300\n",
      "----------\n",
      "train Loss: 0.15960216 Acc: 0.94111498\n",
      "val Loss: 0.81735465 Acc: 0.86548223\n",
      "\n",
      "Epoch 36/300\n",
      "----------\n",
      "train Loss: 0.13670326 Acc: 0.94250871\n",
      "val Loss: 0.90891913 Acc: 0.85532995\n",
      "\n",
      "Epoch 37/300\n",
      "----------\n",
      "train Loss: 0.15159138 Acc: 0.93937282\n",
      "val Loss: 0.86049859 Acc: 0.85786802\n",
      "\n",
      "Epoch 38/300\n",
      "----------\n",
      "train Loss: 0.14751614 Acc: 0.94459930\n",
      "val Loss: 0.86248684 Acc: 0.86294416\n",
      "\n",
      "Epoch 39/300\n",
      "----------\n",
      "train Loss: 0.13447201 Acc: 0.95296167\n",
      "val Loss: 0.81168079 Acc: 0.85279188\n",
      "\n",
      "Epoch 40/300\n",
      "----------\n",
      "train Loss: 0.12835907 Acc: 0.95331010\n",
      "val Loss: 0.85325212 Acc: 0.83756345\n",
      "\n",
      "Epoch 41/300\n",
      "----------\n",
      "train Loss: 0.13658232 Acc: 0.95087108\n",
      "val Loss: 0.72568315 Acc: 0.85025381\n",
      "\n",
      "Epoch 42/300\n",
      "----------\n",
      "train Loss: 0.13822733 Acc: 0.94668990\n",
      "val Loss: 0.86815318 Acc: 0.86040609\n",
      "\n",
      "Epoch 43/300\n",
      "----------\n",
      "train Loss: 0.14028291 Acc: 0.95121951\n",
      "val Loss: 0.77879703 Acc: 0.86548223\n",
      "\n",
      "Epoch 44/300\n",
      "----------\n",
      "train Loss: 0.12988433 Acc: 0.95226481\n",
      "val Loss: 0.79994496 Acc: 0.86294416\n",
      "\n",
      "Epoch 45/300\n",
      "----------\n",
      "train Loss: 0.11481762 Acc: 0.95923345\n",
      "val Loss: 1.01529789 Acc: 0.84010152\n",
      "\n",
      "Epoch 46/300\n",
      "----------\n",
      "train Loss: 0.13557725 Acc: 0.95296167\n",
      "val Loss: 0.87174515 Acc: 0.84771574\n",
      "\n",
      "Epoch 47/300\n",
      "----------\n",
      "train Loss: 0.13290936 Acc: 0.94912892\n",
      "val Loss: 0.94407366 Acc: 0.84010152\n",
      "\n",
      "Epoch 48/300\n",
      "----------\n",
      "train Loss: 0.12324726 Acc: 0.94878049\n",
      "val Loss: 0.71919305 Acc: 0.88071066\n",
      "New best model found!\n",
      "New record ACC: 0.8807106598984771, previous record acc: 0.8730964467005076\n",
      "New record acc is SAVED: 0.8807106598984771\n",
      "\n",
      "Epoch 49/300\n",
      "----------\n",
      "train Loss: 0.13020987 Acc: 0.95331010\n",
      "val Loss: 0.89487426 Acc: 0.84771574\n",
      "\n",
      "Epoch 50/300\n",
      "----------\n",
      "train Loss: 0.13078441 Acc: 0.94808362\n",
      "val Loss: 0.84725874 Acc: 0.85786802\n",
      "\n",
      "Epoch 51/300\n",
      "----------\n",
      "train Loss: 0.13075343 Acc: 0.95226481\n",
      "val Loss: 0.83926953 Acc: 0.85532995\n",
      "\n",
      "Epoch 52/300\n",
      "----------\n",
      "train Loss: 0.11905165 Acc: 0.95574913\n",
      "val Loss: 0.81507018 Acc: 0.87055838\n",
      "\n",
      "Epoch 53/300\n",
      "----------\n",
      "train Loss: 0.11097116 Acc: 0.95644599\n",
      "val Loss: 0.97338365 Acc: 0.85025381\n",
      "\n",
      "Epoch 54/300\n",
      "----------\n",
      "train Loss: 0.11005513 Acc: 0.95783972\n",
      "val Loss: 0.76523013 Acc: 0.88071066\n",
      "\n",
      "Epoch 55/300\n",
      "----------\n",
      "train Loss: 0.13622442 Acc: 0.94878049\n",
      "val Loss: 0.97792942 Acc: 0.82487310\n",
      "\n",
      "Epoch 56/300\n",
      "----------\n",
      "train Loss: 0.11617501 Acc: 0.96097561\n",
      "val Loss: 0.78838969 Acc: 0.86294416\n",
      "\n",
      "Epoch 57/300\n",
      "----------\n",
      "train Loss: 0.12406616 Acc: 0.95365854\n",
      "val Loss: 0.89782712 Acc: 0.85786802\n",
      "\n",
      "Epoch 58/300\n",
      "----------\n",
      "train Loss: 0.13006348 Acc: 0.94564460\n",
      "val Loss: 0.72043426 Acc: 0.87563452\n",
      "\n",
      "Epoch 59/300\n",
      "----------\n",
      "train Loss: 0.11832287 Acc: 0.95331010\n",
      "val Loss: 0.87683624 Acc: 0.86802030\n",
      "\n",
      "Epoch 60/300\n",
      "----------\n",
      "train Loss: 0.11067888 Acc: 0.95714286\n",
      "val Loss: 0.95728925 Acc: 0.85532995\n",
      "\n",
      "Epoch 61/300\n",
      "----------\n",
      "train Loss: 0.11224500 Acc: 0.96027875\n",
      "val Loss: 0.72091669 Acc: 0.87817259\n",
      "\n",
      "Epoch 62/300\n",
      "----------\n",
      "train Loss: 0.12391541 Acc: 0.95331010\n",
      "val Loss: 0.83623443 Acc: 0.85532995\n",
      "\n",
      "Epoch 63/300\n",
      "----------\n",
      "train Loss: 0.11601375 Acc: 0.95296167\n",
      "val Loss: 0.77750770 Acc: 0.86548223\n",
      "\n",
      "Epoch 64/300\n",
      "----------\n",
      "train Loss: 0.11153895 Acc: 0.95958188\n",
      "val Loss: 0.91535906 Acc: 0.85025381\n",
      "\n",
      "Epoch 65/300\n",
      "----------\n",
      "train Loss: 0.09982902 Acc: 0.96236934\n",
      "val Loss: 0.99740855 Acc: 0.84517766\n",
      "\n",
      "Epoch 66/300\n",
      "----------\n",
      "train Loss: 0.10586106 Acc: 0.96062718\n",
      "val Loss: 0.99011189 Acc: 0.82487310\n",
      "\n",
      "Epoch 67/300\n",
      "----------\n",
      "train Loss: 0.08507675 Acc: 0.96689895\n",
      "val Loss: 1.08332094 Acc: 0.82487310\n",
      "\n",
      "Epoch 68/300\n",
      "----------\n",
      "train Loss: 0.11995463 Acc: 0.95540070\n",
      "val Loss: 0.99044802 Acc: 0.84263959\n",
      "\n",
      "Epoch 69/300\n",
      "----------\n",
      "train Loss: 0.11967660 Acc: 0.95853659\n",
      "val Loss: 0.92208028 Acc: 0.85786802\n",
      "\n",
      "Epoch 70/300\n",
      "----------\n",
      "train Loss: 0.12010598 Acc: 0.95261324\n",
      "val Loss: 0.98004517 Acc: 0.85786802\n",
      "\n",
      "Epoch 71/300\n",
      "----------\n",
      "train Loss: 0.09837667 Acc: 0.96202091\n",
      "val Loss: 0.87028614 Acc: 0.86802030\n",
      "\n",
      "Epoch 72/300\n",
      "----------\n",
      "train Loss: 0.10603382 Acc: 0.95609756\n",
      "val Loss: 0.90575012 Acc: 0.85279188\n",
      "\n",
      "Epoch 73/300\n",
      "----------\n",
      "train Loss: 0.10399376 Acc: 0.96236934\n",
      "val Loss: 0.89423827 Acc: 0.86294416\n",
      "\n",
      "Epoch 74/300\n",
      "----------\n",
      "train Loss: 0.11059374 Acc: 0.95505226\n",
      "val Loss: 0.96770041 Acc: 0.86040609\n",
      "\n",
      "Epoch 75/300\n",
      "----------\n",
      "train Loss: 0.09659251 Acc: 0.96794425\n",
      "val Loss: 0.86072594 Acc: 0.87563452\n",
      "\n",
      "Epoch 76/300\n",
      "----------\n",
      "train Loss: 0.08481774 Acc: 0.97142857\n",
      "val Loss: 1.04160502 Acc: 0.85279188\n",
      "\n",
      "Epoch 77/300\n",
      "----------\n",
      "train Loss: 0.09418193 Acc: 0.96550523\n",
      "val Loss: 1.05616560 Acc: 0.84517766\n",
      "\n",
      "Epoch 78/300\n",
      "----------\n",
      "train Loss: 0.10742704 Acc: 0.95714286\n",
      "val Loss: 1.04507839 Acc: 0.85279188\n",
      "\n",
      "Epoch 79/300\n",
      "----------\n",
      "train Loss: 0.10283739 Acc: 0.95749129\n",
      "val Loss: 0.85762016 Acc: 0.87817259\n",
      "\n",
      "Epoch 80/300\n",
      "----------\n",
      "train Loss: 0.09115385 Acc: 0.96376307\n",
      "val Loss: 0.83245405 Acc: 0.87055838\n",
      "\n",
      "Epoch 81/300\n",
      "----------\n",
      "train Loss: 0.11449418 Acc: 0.95296167\n",
      "val Loss: 0.84903275 Acc: 0.88071066\n",
      "\n",
      "Epoch 82/300\n",
      "----------\n",
      "train Loss: 0.09939747 Acc: 0.96167247\n",
      "val Loss: 1.08484216 Acc: 0.84263959\n",
      "\n",
      "Epoch 83/300\n",
      "----------\n",
      "train Loss: 0.09742244 Acc: 0.96620209\n",
      "val Loss: 0.88019476 Acc: 0.86548223\n",
      "\n",
      "Epoch 84/300\n",
      "----------\n",
      "train Loss: 0.10121448 Acc: 0.96306620\n",
      "val Loss: 0.86746261 Acc: 0.85025381\n",
      "\n",
      "Epoch 85/300\n",
      "----------\n",
      "train Loss: 0.09385757 Acc: 0.96585366\n",
      "val Loss: 0.82887535 Acc: 0.87309645\n",
      "\n",
      "Epoch 86/300\n",
      "----------\n",
      "train Loss: 0.09330308 Acc: 0.96306620\n",
      "val Loss: 0.90866976 Acc: 0.84771574\n",
      "\n",
      "Epoch 87/300\n",
      "----------\n",
      "train Loss: 0.09447133 Acc: 0.96655052\n",
      "val Loss: 0.82059193 Acc: 0.85279188\n",
      "\n",
      "Epoch 88/300\n",
      "----------\n",
      "train Loss: 0.10365821 Acc: 0.95783972\n",
      "val Loss: 0.86971073 Acc: 0.86294416\n",
      "\n",
      "Epoch 89/300\n",
      "----------\n",
      "train Loss: 0.09367030 Acc: 0.96585366\n",
      "val Loss: 0.92062195 Acc: 0.86294416\n",
      "\n",
      "Epoch 90/300\n",
      "----------\n",
      "train Loss: 0.09292261 Acc: 0.96306620\n",
      "val Loss: 0.86149348 Acc: 0.86294416\n",
      "\n",
      "Epoch 91/300\n",
      "----------\n",
      "train Loss: 0.09438089 Acc: 0.95993031\n",
      "val Loss: 0.91001780 Acc: 0.85279188\n",
      "\n",
      "Epoch 92/300\n",
      "----------\n",
      "train Loss: 0.09294648 Acc: 0.96620209\n",
      "val Loss: 0.98980407 Acc: 0.85025381\n",
      "\n",
      "Epoch 93/300\n",
      "----------\n",
      "train Loss: 0.09507358 Acc: 0.96620209\n",
      "val Loss: 0.91218606 Acc: 0.85279188\n",
      "\n",
      "Epoch 94/300\n",
      "----------\n",
      "train Loss: 0.09596177 Acc: 0.96097561\n",
      "val Loss: 1.01083690 Acc: 0.85532995\n",
      "\n",
      "Epoch 95/300\n",
      "----------\n",
      "train Loss: 0.08284829 Acc: 0.97142857\n",
      "val Loss: 1.05704010 Acc: 0.84771574\n",
      "\n",
      "Epoch 96/300\n",
      "----------\n",
      "train Loss: 0.10052961 Acc: 0.96306620\n",
      "val Loss: 0.85921104 Acc: 0.86548223\n",
      "\n",
      "Epoch 97/300\n",
      "----------\n",
      "train Loss: 0.07798681 Acc: 0.97282230\n",
      "val Loss: 1.01899052 Acc: 0.85025381\n",
      "\n",
      "Epoch 98/300\n",
      "----------\n",
      "train Loss: 0.08751295 Acc: 0.96620209\n",
      "val Loss: 1.05877799 Acc: 0.84771574\n",
      "\n",
      "Epoch 99/300\n",
      "----------\n",
      "train Loss: 0.10475023 Acc: 0.96271777\n",
      "val Loss: 1.06249205 Acc: 0.84263959\n",
      "\n",
      "Epoch 100/300\n",
      "----------\n",
      "train Loss: 0.09489815 Acc: 0.96724739\n",
      "val Loss: 1.04421370 Acc: 0.84517766\n",
      "\n",
      "Epoch 101/300\n",
      "----------\n",
      "train Loss: 0.09725965 Acc: 0.96236934\n",
      "val Loss: 1.01398395 Acc: 0.83502538\n",
      "\n",
      "Epoch 102/300\n",
      "----------\n",
      "train Loss: 0.09394248 Acc: 0.96550523\n",
      "val Loss: 1.02716167 Acc: 0.84010152\n",
      "\n",
      "Epoch 103/300\n",
      "----------\n",
      "train Loss: 0.08997876 Acc: 0.96411150\n",
      "val Loss: 1.01585042 Acc: 0.85279188\n",
      "\n",
      "Epoch 104/300\n",
      "----------\n",
      "train Loss: 0.08083769 Acc: 0.97038328\n",
      "val Loss: 0.93787472 Acc: 0.86040609\n",
      "\n",
      "Epoch 105/300\n",
      "----------\n",
      "train Loss: 0.08271900 Acc: 0.96968641\n",
      "val Loss: 1.02871685 Acc: 0.84263959\n",
      "\n",
      "Epoch 106/300\n",
      "----------\n",
      "train Loss: 0.08832030 Acc: 0.96550523\n",
      "val Loss: 0.99972126 Acc: 0.84517766\n",
      "\n",
      "Epoch 107/300\n",
      "----------\n",
      "train Loss: 0.07220736 Acc: 0.97247387\n",
      "val Loss: 1.01376349 Acc: 0.84517766\n",
      "\n",
      "Epoch 108/300\n",
      "----------\n",
      "train Loss: 0.07862614 Acc: 0.97212544\n",
      "val Loss: 1.03895210 Acc: 0.84263959\n",
      "\n",
      "Epoch 109/300\n",
      "----------\n",
      "train Loss: 0.07770797 Acc: 0.97351916\n",
      "val Loss: 1.04100939 Acc: 0.84010152\n",
      "\n",
      "Epoch 110/300\n",
      "----------\n",
      "train Loss: 0.07985603 Acc: 0.96829268\n",
      "val Loss: 1.00345227 Acc: 0.84263959\n",
      "\n",
      "Epoch 111/300\n",
      "----------\n",
      "train Loss: 0.07074235 Acc: 0.97630662\n",
      "val Loss: 0.97565555 Acc: 0.85279188\n",
      "\n",
      "Epoch 112/300\n",
      "----------\n",
      "train Loss: 0.07048185 Acc: 0.97177700\n",
      "val Loss: 0.97851183 Acc: 0.85279188\n",
      "\n",
      "Epoch 113/300\n",
      "----------\n",
      "train Loss: 0.06919269 Acc: 0.97351916\n",
      "val Loss: 0.98597597 Acc: 0.84517766\n",
      "\n",
      "Epoch 114/300\n",
      "----------\n",
      "train Loss: 0.08456052 Acc: 0.96480836\n",
      "val Loss: 1.00282201 Acc: 0.84517766\n",
      "\n",
      "Epoch 115/300\n",
      "----------\n",
      "train Loss: 0.08575680 Acc: 0.96689895\n",
      "val Loss: 1.02503729 Acc: 0.84263959\n",
      "\n",
      "Epoch 116/300\n",
      "----------\n",
      "train Loss: 0.06801869 Acc: 0.97560976\n",
      "val Loss: 1.05293577 Acc: 0.83756345\n",
      "\n",
      "Epoch 117/300\n",
      "----------\n",
      "train Loss: 0.07425756 Acc: 0.97142857\n",
      "val Loss: 1.05335911 Acc: 0.83756345\n",
      "\n",
      "Epoch 118/300\n",
      "----------\n",
      "train Loss: 0.07401856 Acc: 0.97038328\n",
      "val Loss: 1.01440618 Acc: 0.84263959\n",
      "\n",
      "Epoch 119/300\n",
      "----------\n",
      "train Loss: 0.07014617 Acc: 0.97456446\n",
      "val Loss: 1.01481758 Acc: 0.84263959\n",
      "\n",
      "Epoch 120/300\n",
      "----------\n",
      "train Loss: 0.07229694 Acc: 0.97142857\n",
      "val Loss: 0.97351696 Acc: 0.85279188\n",
      "\n",
      "Epoch 121/300\n",
      "----------\n",
      "train Loss: 0.07993643 Acc: 0.97212544\n",
      "val Loss: 0.98913876 Acc: 0.84263959\n",
      "\n",
      "Epoch 122/300\n",
      "----------\n",
      "train Loss: 0.07407001 Acc: 0.97177700\n",
      "val Loss: 0.97324584 Acc: 0.84517766\n",
      "\n",
      "Epoch 123/300\n",
      "----------\n",
      "train Loss: 0.07247125 Acc: 0.97595819\n",
      "val Loss: 0.99276237 Acc: 0.84263959\n",
      "\n",
      "Epoch 124/300\n",
      "----------\n",
      "train Loss: 0.06947184 Acc: 0.97421603\n",
      "val Loss: 1.01734725 Acc: 0.83756345\n",
      "\n",
      "Epoch 125/300\n",
      "----------\n",
      "train Loss: 0.07016267 Acc: 0.97630662\n",
      "val Loss: 0.99499517 Acc: 0.83756345\n",
      "\n",
      "Epoch 126/300\n",
      "----------\n",
      "train Loss: 0.06965767 Acc: 0.97421603\n",
      "val Loss: 0.95974770 Acc: 0.85025381\n",
      "\n",
      "Epoch 127/300\n",
      "----------\n",
      "train Loss: 0.07834058 Acc: 0.97108014\n",
      "val Loss: 1.02424939 Acc: 0.83756345\n",
      "\n",
      "Epoch 128/300\n",
      "----------\n",
      "train Loss: 0.07197815 Acc: 0.97317073\n",
      "val Loss: 1.00678010 Acc: 0.83756345\n",
      "\n",
      "Epoch 129/300\n",
      "----------\n",
      "train Loss: 0.07235362 Acc: 0.97212544\n",
      "val Loss: 1.01296247 Acc: 0.84010152\n",
      "\n",
      "Epoch 130/300\n",
      "----------\n",
      "train Loss: 0.08350427 Acc: 0.97038328\n",
      "val Loss: 1.00765561 Acc: 0.84263959\n",
      "\n",
      "Epoch 131/300\n",
      "----------\n",
      "train Loss: 0.06725197 Acc: 0.97456446\n",
      "val Loss: 1.05439912 Acc: 0.83502538\n",
      "\n",
      "Epoch 132/300\n",
      "----------\n",
      "train Loss: 0.07248756 Acc: 0.97282230\n",
      "val Loss: 0.96439139 Acc: 0.85279188\n",
      "\n",
      "Epoch 133/300\n",
      "----------\n",
      "train Loss: 0.06636768 Acc: 0.97770035\n",
      "val Loss: 0.96451877 Acc: 0.85279188\n",
      "\n",
      "Epoch 134/300\n",
      "----------\n",
      "train Loss: 0.07161626 Acc: 0.97073171\n",
      "val Loss: 1.00000574 Acc: 0.84263959\n",
      "\n",
      "Epoch 135/300\n",
      "----------\n",
      "train Loss: 0.08244092 Acc: 0.97003484\n",
      "val Loss: 0.98980846 Acc: 0.84517766\n",
      "\n",
      "Epoch 136/300\n",
      "----------\n",
      "train Loss: 0.08008969 Acc: 0.97003484\n",
      "val Loss: 1.01432502 Acc: 0.84263959\n",
      "\n",
      "Epoch 137/300\n",
      "----------\n",
      "train Loss: 0.08308322 Acc: 0.97177700\n",
      "val Loss: 1.00031724 Acc: 0.84263959\n",
      "\n",
      "Epoch 138/300\n",
      "----------\n",
      "train Loss: 0.07926653 Acc: 0.96864111\n",
      "val Loss: 1.01982399 Acc: 0.85532995\n",
      "\n",
      "Epoch 139/300\n",
      "----------\n",
      "train Loss: 0.07414587 Acc: 0.97003484\n",
      "val Loss: 1.00870434 Acc: 0.84010152\n",
      "\n",
      "Epoch 140/300\n",
      "----------\n",
      "train Loss: 0.06270877 Acc: 0.97630662\n",
      "val Loss: 0.98679042 Acc: 0.85025381\n",
      "\n",
      "Epoch 141/300\n",
      "----------\n",
      "train Loss: 0.06774495 Acc: 0.97317073\n",
      "val Loss: 0.98392602 Acc: 0.85025381\n",
      "\n",
      "Epoch 142/300\n",
      "----------\n",
      "train Loss: 0.06407914 Acc: 0.97630662\n",
      "val Loss: 1.01109892 Acc: 0.83756345\n",
      "\n",
      "Epoch 143/300\n",
      "----------\n",
      "train Loss: 0.07172948 Acc: 0.97282230\n",
      "val Loss: 1.05504531 Acc: 0.83502538\n",
      "\n",
      "Epoch 144/300\n",
      "----------\n",
      "train Loss: 0.07410137 Acc: 0.97421603\n",
      "val Loss: 0.99740567 Acc: 0.85279188\n",
      "\n",
      "Epoch 145/300\n",
      "----------\n",
      "train Loss: 0.07027413 Acc: 0.97177700\n",
      "val Loss: 1.01965990 Acc: 0.84263959\n",
      "\n",
      "Epoch 146/300\n",
      "----------\n",
      "train Loss: 0.06451706 Acc: 0.97351916\n",
      "val Loss: 0.99176833 Acc: 0.83502538\n",
      "\n",
      "Epoch 147/300\n",
      "----------\n",
      "train Loss: 0.07965094 Acc: 0.96898955\n",
      "val Loss: 1.02993207 Acc: 0.85025381\n",
      "\n",
      "Epoch 148/300\n",
      "----------\n",
      "train Loss: 0.07256254 Acc: 0.97073171\n",
      "val Loss: 1.03764737 Acc: 0.85025381\n",
      "\n",
      "Epoch 149/300\n",
      "----------\n",
      "train Loss: 0.07445769 Acc: 0.97456446\n",
      "val Loss: 1.03291980 Acc: 0.83756345\n",
      "\n",
      "Epoch 150/300\n",
      "----------\n",
      "train Loss: 0.06725542 Acc: 0.97630662\n",
      "val Loss: 1.04981241 Acc: 0.83756345\n",
      "\n",
      "Epoch 151/300\n",
      "----------\n",
      "train Loss: 0.08547937 Acc: 0.97282230\n",
      "val Loss: 1.01094483 Acc: 0.84517766\n",
      "\n",
      "Epoch 152/300\n",
      "----------\n",
      "train Loss: 0.07353764 Acc: 0.97386760\n",
      "val Loss: 1.09656203 Acc: 0.83248731\n",
      "\n",
      "Epoch 153/300\n",
      "----------\n",
      "train Loss: 0.08129494 Acc: 0.97108014\n",
      "val Loss: 1.09611709 Acc: 0.83502538\n",
      "\n",
      "Epoch 154/300\n",
      "----------\n",
      "train Loss: 0.06999536 Acc: 0.97282230\n",
      "val Loss: 1.01970088 Acc: 0.83756345\n",
      "\n",
      "Epoch 155/300\n",
      "----------\n",
      "train Loss: 0.06185159 Acc: 0.97526132\n",
      "val Loss: 1.01222857 Acc: 0.85279188\n",
      "\n",
      "Epoch 156/300\n",
      "----------\n",
      "train Loss: 0.06603000 Acc: 0.97456446\n",
      "val Loss: 1.01908333 Acc: 0.83502538\n",
      "\n",
      "Epoch 157/300\n",
      "----------\n",
      "train Loss: 0.07896787 Acc: 0.96968641\n",
      "val Loss: 1.09279824 Acc: 0.83248731\n",
      "\n",
      "Epoch 158/300\n",
      "----------\n",
      "train Loss: 0.06345909 Acc: 0.97386760\n",
      "val Loss: 1.02363858 Acc: 0.83756345\n",
      "\n",
      "Epoch 159/300\n",
      "----------\n",
      "train Loss: 0.06943947 Acc: 0.97282230\n",
      "val Loss: 1.03214188 Acc: 0.83756345\n",
      "\n",
      "Epoch 160/300\n",
      "----------\n",
      "train Loss: 0.07224892 Acc: 0.97456446\n",
      "val Loss: 1.10466415 Acc: 0.83248731\n",
      "\n",
      "Epoch 161/300\n",
      "----------\n",
      "train Loss: 0.06573976 Acc: 0.97456446\n",
      "val Loss: 1.07503814 Acc: 0.83756345\n",
      "\n",
      "Epoch 162/300\n",
      "----------\n",
      "train Loss: 0.05738755 Acc: 0.97804878\n",
      "val Loss: 1.03335535 Acc: 0.83756345\n",
      "\n",
      "Epoch 163/300\n",
      "----------\n",
      "train Loss: 0.06598657 Acc: 0.97735192\n",
      "val Loss: 1.04599097 Acc: 0.83756345\n",
      "\n",
      "Epoch 164/300\n",
      "----------\n",
      "train Loss: 0.06574381 Acc: 0.97282230\n",
      "val Loss: 1.00080409 Acc: 0.83756345\n",
      "\n",
      "Epoch 165/300\n",
      "----------\n",
      "train Loss: 0.06458915 Acc: 0.97560976\n",
      "val Loss: 1.07246206 Acc: 0.83756345\n",
      "\n",
      "Epoch 166/300\n",
      "----------\n",
      "train Loss: 0.07135538 Acc: 0.97108014\n",
      "val Loss: 1.01755578 Acc: 0.83756345\n",
      "\n",
      "Epoch 167/300\n",
      "----------\n",
      "train Loss: 0.06420452 Acc: 0.97874564\n",
      "val Loss: 1.01960928 Acc: 0.83756345\n",
      "\n",
      "Epoch 168/300\n",
      "----------\n",
      "train Loss: 0.07296214 Acc: 0.97212544\n",
      "val Loss: 1.04346283 Acc: 0.83502538\n",
      "\n",
      "Epoch 169/300\n",
      "----------\n",
      "train Loss: 0.06512662 Acc: 0.97526132\n",
      "val Loss: 1.02729660 Acc: 0.83756345\n",
      "\n",
      "Epoch 170/300\n",
      "----------\n",
      "train Loss: 0.06689826 Acc: 0.97700348\n",
      "val Loss: 1.06521813 Acc: 0.83502538\n",
      "\n",
      "Epoch 171/300\n",
      "----------\n",
      "train Loss: 0.05840881 Acc: 0.97909408\n",
      "val Loss: 1.00438788 Acc: 0.84517766\n",
      "\n",
      "Epoch 172/300\n",
      "----------\n",
      "train Loss: 0.05792941 Acc: 0.98083624\n",
      "val Loss: 1.01982155 Acc: 0.84517766\n",
      "\n",
      "Epoch 173/300\n",
      "----------\n",
      "train Loss: 0.07475865 Acc: 0.97003484\n",
      "val Loss: 1.00404207 Acc: 0.84010152\n",
      "\n",
      "Epoch 174/300\n",
      "----------\n",
      "train Loss: 0.06204028 Acc: 0.97665505\n",
      "val Loss: 1.00327708 Acc: 0.84010152\n",
      "\n",
      "Epoch 175/300\n",
      "----------\n",
      "train Loss: 0.06015164 Acc: 0.97909408\n",
      "val Loss: 1.07241443 Acc: 0.83502538\n",
      "\n",
      "Epoch 176/300\n",
      "----------\n",
      "train Loss: 0.06472376 Acc: 0.97700348\n",
      "val Loss: 1.02576448 Acc: 0.84263959\n",
      "\n",
      "Epoch 177/300\n",
      "----------\n",
      "train Loss: 0.06207638 Acc: 0.97595819\n",
      "val Loss: 1.08511668 Acc: 0.83502538\n",
      "\n",
      "Epoch 178/300\n",
      "----------\n",
      "train Loss: 0.06780895 Acc: 0.97560976\n",
      "val Loss: 1.06333048 Acc: 0.83502538\n",
      "\n",
      "Epoch 179/300\n",
      "----------\n",
      "train Loss: 0.06560012 Acc: 0.97735192\n",
      "val Loss: 1.02924121 Acc: 0.83502538\n",
      "\n",
      "Epoch 180/300\n",
      "----------\n",
      "train Loss: 0.07766786 Acc: 0.97038328\n",
      "val Loss: 1.08079279 Acc: 0.82994924\n",
      "\n",
      "Epoch 181/300\n",
      "----------\n",
      "train Loss: 0.06254610 Acc: 0.97595819\n",
      "val Loss: 1.05486585 Acc: 0.83248731\n",
      "\n",
      "Epoch 182/300\n",
      "----------\n",
      "train Loss: 0.07570649 Acc: 0.97073171\n",
      "val Loss: 1.10335294 Acc: 0.82994924\n",
      "\n",
      "Epoch 183/300\n",
      "----------\n",
      "train Loss: 0.07070220 Acc: 0.97212544\n",
      "val Loss: 1.06061565 Acc: 0.83502538\n",
      "\n",
      "Epoch 184/300\n",
      "----------\n",
      "train Loss: 0.06569042 Acc: 0.97491289\n",
      "val Loss: 1.04710837 Acc: 0.83248731\n",
      "\n",
      "Epoch 185/300\n",
      "----------\n",
      "train Loss: 0.07390794 Acc: 0.96933798\n",
      "val Loss: 1.04939615 Acc: 0.83248731\n",
      "\n",
      "Epoch 186/300\n",
      "----------\n",
      "train Loss: 0.06182619 Acc: 0.97421603\n",
      "val Loss: 1.10154412 Acc: 0.82994924\n",
      "\n",
      "Epoch 187/300\n",
      "----------\n",
      "train Loss: 0.06277377 Acc: 0.97909408\n",
      "val Loss: 1.10633358 Acc: 0.83248731\n",
      "\n",
      "Epoch 188/300\n",
      "----------\n",
      "train Loss: 0.07103488 Acc: 0.97421603\n",
      "val Loss: 1.08490333 Acc: 0.83756345\n",
      "\n",
      "Epoch 189/300\n",
      "----------\n",
      "train Loss: 0.07071052 Acc: 0.97386760\n",
      "val Loss: 1.05829950 Acc: 0.83502538\n",
      "\n",
      "Epoch 190/300\n",
      "----------\n",
      "train Loss: 0.07279509 Acc: 0.97003484\n",
      "val Loss: 1.11546468 Acc: 0.82741117\n",
      "\n",
      "Epoch 191/300\n",
      "----------\n",
      "train Loss: 0.07120555 Acc: 0.97526132\n",
      "val Loss: 1.12885446 Acc: 0.83248731\n",
      "\n",
      "Epoch 192/300\n",
      "----------\n",
      "train Loss: 0.06583698 Acc: 0.97630662\n",
      "val Loss: 1.13567046 Acc: 0.82994924\n",
      "\n",
      "Epoch 193/300\n",
      "----------\n",
      "train Loss: 0.06551414 Acc: 0.97735192\n",
      "val Loss: 1.08502085 Acc: 0.82994924\n",
      "\n",
      "Epoch 194/300\n",
      "----------\n",
      "train Loss: 0.07494981 Acc: 0.97212544\n",
      "val Loss: 1.05007466 Acc: 0.83502538\n",
      "\n",
      "Epoch 195/300\n",
      "----------\n",
      "train Loss: 0.07557647 Acc: 0.97142857\n",
      "val Loss: 1.03615484 Acc: 0.83502538\n",
      "\n",
      "Epoch 196/300\n",
      "----------\n",
      "train Loss: 0.06244856 Acc: 0.97735192\n",
      "val Loss: 1.08108302 Acc: 0.83248731\n",
      "\n",
      "Epoch 197/300\n",
      "----------\n",
      "train Loss: 0.06691160 Acc: 0.97665505\n",
      "val Loss: 1.02859240 Acc: 0.83502538\n",
      "\n",
      "Epoch 198/300\n",
      "----------\n",
      "train Loss: 0.08252575 Acc: 0.96759582\n",
      "val Loss: 1.04322632 Acc: 0.83248731\n",
      "\n",
      "Epoch 199/300\n",
      "----------\n",
      "train Loss: 0.06015026 Acc: 0.97630662\n",
      "val Loss: 1.00460994 Acc: 0.83756345\n",
      "\n",
      "Epoch 200/300\n",
      "----------\n",
      "train Loss: 0.07257420 Acc: 0.97073171\n",
      "val Loss: 1.02645495 Acc: 0.83756345\n",
      "\n",
      "Epoch 201/300\n",
      "----------\n",
      "train Loss: 0.05601537 Acc: 0.97839721\n",
      "val Loss: 1.06212532 Acc: 0.83756345\n",
      "\n",
      "Epoch 202/300\n",
      "----------\n",
      "train Loss: 0.06275973 Acc: 0.97526132\n",
      "val Loss: 1.10766780 Acc: 0.82994924\n",
      "\n",
      "Epoch 203/300\n",
      "----------\n",
      "train Loss: 0.06072288 Acc: 0.97804878\n",
      "val Loss: 1.06799486 Acc: 0.83756345\n",
      "\n",
      "Epoch 204/300\n",
      "----------\n",
      "train Loss: 0.06546045 Acc: 0.97491289\n",
      "val Loss: 1.04982142 Acc: 0.83756345\n",
      "\n",
      "Epoch 205/300\n",
      "----------\n",
      "train Loss: 0.07247931 Acc: 0.97317073\n",
      "val Loss: 1.04307575 Acc: 0.83502538\n",
      "\n",
      "Epoch 206/300\n",
      "----------\n",
      "train Loss: 0.05861864 Acc: 0.97595819\n",
      "val Loss: 1.03371825 Acc: 0.83756345\n",
      "\n",
      "Epoch 207/300\n",
      "----------\n",
      "train Loss: 0.07724986 Acc: 0.97351916\n",
      "val Loss: 1.02651801 Acc: 0.83756345\n",
      "\n",
      "Epoch 208/300\n",
      "----------\n",
      "train Loss: 0.07047806 Acc: 0.97351916\n",
      "val Loss: 1.06543890 Acc: 0.83502538\n",
      "\n",
      "Epoch 209/300\n",
      "----------\n",
      "train Loss: 0.06841368 Acc: 0.97421603\n",
      "val Loss: 1.00775867 Acc: 0.83756345\n",
      "\n",
      "Epoch 210/300\n",
      "----------\n",
      "train Loss: 0.06227917 Acc: 0.97944251\n",
      "val Loss: 1.03265973 Acc: 0.83756345\n",
      "\n",
      "Epoch 211/300\n",
      "----------\n",
      "train Loss: 0.06249717 Acc: 0.97630662\n",
      "val Loss: 1.04964024 Acc: 0.83502538\n",
      "\n",
      "Epoch 212/300\n",
      "----------\n",
      "train Loss: 0.06738474 Acc: 0.97595819\n",
      "val Loss: 1.06115330 Acc: 0.83248731\n",
      "\n",
      "Epoch 213/300\n",
      "----------\n",
      "train Loss: 0.07129449 Acc: 0.97247387\n",
      "val Loss: 1.06701146 Acc: 0.83248731\n",
      "\n",
      "Epoch 214/300\n",
      "----------\n",
      "train Loss: 0.06251843 Acc: 0.97526132\n",
      "val Loss: 1.02470637 Acc: 0.83502538\n",
      "\n",
      "Epoch 215/300\n",
      "----------\n",
      "train Loss: 0.06258855 Acc: 0.97526132\n",
      "val Loss: 1.03417007 Acc: 0.83502538\n",
      "\n",
      "Epoch 216/300\n",
      "----------\n",
      "train Loss: 0.06718218 Acc: 0.97351916\n",
      "val Loss: 1.01344285 Acc: 0.83756345\n",
      "\n",
      "Epoch 217/300\n",
      "----------\n",
      "train Loss: 0.06593302 Acc: 0.97595819\n",
      "val Loss: 1.05661146 Acc: 0.83248731\n",
      "\n",
      "Epoch 218/300\n",
      "----------\n",
      "train Loss: 0.06347822 Acc: 0.97595819\n",
      "val Loss: 1.10014391 Acc: 0.83248731\n",
      "\n",
      "Epoch 219/300\n",
      "----------\n",
      "train Loss: 0.06205101 Acc: 0.97735192\n",
      "val Loss: 1.03476895 Acc: 0.83756345\n",
      "\n",
      "Epoch 220/300\n",
      "----------\n",
      "train Loss: 0.06347096 Acc: 0.97665505\n",
      "val Loss: 1.03592882 Acc: 0.83756345\n",
      "\n",
      "Epoch 221/300\n",
      "----------\n",
      "train Loss: 0.07925843 Acc: 0.96898955\n",
      "val Loss: 1.02609365 Acc: 0.83248731\n",
      "\n",
      "Epoch 222/300\n",
      "----------\n",
      "train Loss: 0.06211079 Acc: 0.97595819\n",
      "val Loss: 0.99947816 Acc: 0.83756345\n",
      "\n",
      "Epoch 223/300\n",
      "----------\n",
      "train Loss: 0.06076925 Acc: 0.97839721\n",
      "val Loss: 1.08397577 Acc: 0.83248731\n",
      "\n",
      "Epoch 224/300\n",
      "----------\n",
      "train Loss: 0.06608727 Acc: 0.97560976\n",
      "val Loss: 1.05011315 Acc: 0.83248731\n",
      "\n",
      "Epoch 225/300\n",
      "----------\n",
      "train Loss: 0.06630245 Acc: 0.97212544\n",
      "val Loss: 1.02617740 Acc: 0.83248731\n",
      "\n",
      "Epoch 226/300\n",
      "----------\n",
      "train Loss: 0.05628298 Acc: 0.97735192\n",
      "val Loss: 1.05035622 Acc: 0.83248731\n",
      "\n",
      "Epoch 227/300\n",
      "----------\n",
      "train Loss: 0.07633370 Acc: 0.97317073\n",
      "val Loss: 1.06188292 Acc: 0.83502538\n",
      "\n",
      "Epoch 228/300\n",
      "----------\n",
      "train Loss: 0.06526262 Acc: 0.97665505\n",
      "val Loss: 1.04719594 Acc: 0.83502538\n",
      "\n",
      "Epoch 229/300\n",
      "----------\n",
      "train Loss: 0.07277507 Acc: 0.97317073\n",
      "val Loss: 1.03906271 Acc: 0.83502538\n",
      "\n",
      "Epoch 230/300\n",
      "----------\n",
      "train Loss: 0.05930859 Acc: 0.98083624\n",
      "val Loss: 0.99725996 Acc: 0.83756345\n",
      "\n",
      "Epoch 231/300\n",
      "----------\n",
      "train Loss: 0.07539373 Acc: 0.96968641\n",
      "val Loss: 1.06040256 Acc: 0.83502538\n",
      "\n",
      "Epoch 232/300\n",
      "----------\n",
      "train Loss: 0.06590373 Acc: 0.97560976\n",
      "val Loss: 1.05467453 Acc: 0.83502538\n",
      "\n",
      "Epoch 233/300\n",
      "----------\n",
      "train Loss: 0.07537008 Acc: 0.97142857\n",
      "val Loss: 1.06018538 Acc: 0.83502538\n",
      "\n",
      "Epoch 234/300\n",
      "----------\n",
      "train Loss: 0.07224925 Acc: 0.97038328\n",
      "val Loss: 1.08709865 Acc: 0.83502538\n",
      "\n",
      "Epoch 235/300\n",
      "----------\n",
      "train Loss: 0.06082491 Acc: 0.97456446\n",
      "val Loss: 1.03798113 Acc: 0.83756345\n",
      "\n",
      "Epoch 236/300\n",
      "----------\n",
      "train Loss: 0.06185952 Acc: 0.97386760\n",
      "val Loss: 1.04057042 Acc: 0.83502538\n",
      "\n",
      "Epoch 237/300\n",
      "----------\n",
      "train Loss: 0.06650733 Acc: 0.97491289\n",
      "val Loss: 1.05237551 Acc: 0.83248731\n",
      "\n",
      "Epoch 238/300\n",
      "----------\n",
      "train Loss: 0.05497462 Acc: 0.97560976\n",
      "val Loss: 1.04456938 Acc: 0.83756345\n",
      "\n",
      "Epoch 239/300\n",
      "----------\n",
      "train Loss: 0.06791956 Acc: 0.97665505\n",
      "val Loss: 1.02835759 Acc: 0.83502538\n",
      "\n",
      "Epoch 240/300\n",
      "----------\n",
      "train Loss: 0.06885474 Acc: 0.97351916\n",
      "val Loss: 1.00060961 Acc: 0.83502538\n",
      "\n",
      "Epoch 241/300\n",
      "----------\n",
      "train Loss: 0.06308317 Acc: 0.97630662\n",
      "val Loss: 1.03133003 Acc: 0.83502538\n",
      "\n",
      "Epoch 242/300\n",
      "----------\n",
      "train Loss: 0.07137678 Acc: 0.97421603\n",
      "val Loss: 1.09370072 Acc: 0.82994924\n",
      "\n",
      "Epoch 243/300\n",
      "----------\n",
      "train Loss: 0.06948400 Acc: 0.97247387\n",
      "val Loss: 1.05611109 Acc: 0.83502538\n",
      "\n",
      "Epoch 244/300\n",
      "----------\n",
      "train Loss: 0.06933794 Acc: 0.97386760\n",
      "val Loss: 1.05449402 Acc: 0.83502538\n",
      "\n",
      "Epoch 245/300\n",
      "----------\n",
      "train Loss: 0.07307719 Acc: 0.97317073\n",
      "val Loss: 1.03379027 Acc: 0.83756345\n",
      "\n",
      "Epoch 246/300\n",
      "----------\n",
      "train Loss: 0.07073234 Acc: 0.97665505\n",
      "val Loss: 1.05740957 Acc: 0.83248731\n",
      "\n",
      "Epoch 247/300\n",
      "----------\n",
      "train Loss: 0.04927148 Acc: 0.98257840\n",
      "val Loss: 1.01194506 Acc: 0.83756345\n",
      "\n",
      "Epoch 248/300\n",
      "----------\n",
      "train Loss: 0.06771940 Acc: 0.97526132\n",
      "val Loss: 1.06176826 Acc: 0.83248731\n",
      "\n",
      "Epoch 249/300\n",
      "----------\n",
      "train Loss: 0.06059054 Acc: 0.97526132\n",
      "val Loss: 1.08750403 Acc: 0.83502538\n",
      "\n",
      "Epoch 250/300\n",
      "----------\n",
      "train Loss: 0.06353037 Acc: 0.97595819\n",
      "val Loss: 1.04372590 Acc: 0.83502538\n",
      "\n",
      "Epoch 251/300\n",
      "----------\n",
      "train Loss: 0.06066716 Acc: 0.98083624\n",
      "val Loss: 1.05725013 Acc: 0.83248731\n",
      "\n",
      "Epoch 252/300\n",
      "----------\n",
      "train Loss: 0.06947216 Acc: 0.97073171\n",
      "val Loss: 1.00009332 Acc: 0.83756345\n",
      "\n",
      "Epoch 253/300\n",
      "----------\n",
      "train Loss: 0.06402105 Acc: 0.97560976\n",
      "val Loss: 1.03773497 Acc: 0.83248731\n",
      "\n",
      "Epoch 254/300\n",
      "----------\n",
      "train Loss: 0.06040809 Acc: 0.97804878\n",
      "val Loss: 1.04703820 Acc: 0.83248731\n",
      "\n",
      "Epoch 255/300\n",
      "----------\n",
      "train Loss: 0.06337861 Acc: 0.97665505\n",
      "val Loss: 0.99719450 Acc: 0.83502538\n",
      "\n",
      "Epoch 256/300\n",
      "----------\n",
      "train Loss: 0.06440810 Acc: 0.97804878\n",
      "val Loss: 1.03428526 Acc: 0.83502538\n",
      "\n",
      "Epoch 257/300\n",
      "----------\n",
      "train Loss: 0.06120474 Acc: 0.97386760\n",
      "val Loss: 1.08755079 Acc: 0.83248731\n",
      "\n",
      "Epoch 258/300\n",
      "----------\n",
      "train Loss: 0.06599527 Acc: 0.97770035\n",
      "val Loss: 1.05434688 Acc: 0.83248731\n",
      "\n",
      "Epoch 259/300\n",
      "----------\n",
      "train Loss: 0.05642729 Acc: 0.98153310\n",
      "val Loss: 0.99850738 Acc: 0.83756345\n",
      "\n",
      "Epoch 260/300\n",
      "----------\n",
      "train Loss: 0.06796981 Acc: 0.97456446\n",
      "val Loss: 1.04164332 Acc: 0.83502538\n",
      "\n",
      "Epoch 261/300\n",
      "----------\n",
      "train Loss: 0.05899947 Acc: 0.97770035\n",
      "val Loss: 1.06119443 Acc: 0.83502538\n",
      "\n",
      "Epoch 262/300\n",
      "----------\n",
      "train Loss: 0.05930450 Acc: 0.97700348\n",
      "val Loss: 1.06555941 Acc: 0.83248731\n",
      "\n",
      "Epoch 263/300\n",
      "----------\n",
      "train Loss: 0.06663912 Acc: 0.97456446\n",
      "val Loss: 1.05548657 Acc: 0.84010152\n",
      "\n",
      "Epoch 264/300\n",
      "----------\n",
      "train Loss: 0.06701603 Acc: 0.97630662\n",
      "val Loss: 1.09245087 Acc: 0.83248731\n",
      "\n",
      "Epoch 265/300\n",
      "----------\n",
      "train Loss: 0.06853300 Acc: 0.97386760\n",
      "val Loss: 1.03242253 Acc: 0.83502538\n",
      "\n",
      "Epoch 266/300\n",
      "----------\n",
      "train Loss: 0.06900618 Acc: 0.97560976\n",
      "val Loss: 1.04792844 Acc: 0.83502538\n",
      "\n",
      "Epoch 267/300\n",
      "----------\n",
      "train Loss: 0.07361440 Acc: 0.97142857\n",
      "val Loss: 1.03909232 Acc: 0.83248731\n",
      "\n",
      "Epoch 268/300\n",
      "----------\n",
      "train Loss: 0.07474664 Acc: 0.97247387\n",
      "val Loss: 1.07916578 Acc: 0.83248731\n",
      "\n",
      "Epoch 269/300\n",
      "----------\n",
      "train Loss: 0.05810225 Acc: 0.97839721\n",
      "val Loss: 1.05838315 Acc: 0.83248731\n",
      "\n",
      "Epoch 270/300\n",
      "----------\n",
      "train Loss: 0.06733628 Acc: 0.97526132\n",
      "val Loss: 1.06276501 Acc: 0.83502538\n",
      "\n",
      "Epoch 271/300\n",
      "----------\n",
      "train Loss: 0.06178406 Acc: 0.97700348\n",
      "val Loss: 1.06232627 Acc: 0.83502538\n",
      "\n",
      "Epoch 272/300\n",
      "----------\n",
      "train Loss: 0.05581387 Acc: 0.97874564\n",
      "val Loss: 1.09408656 Acc: 0.82741117\n",
      "\n",
      "Epoch 273/300\n",
      "----------\n",
      "train Loss: 0.06346258 Acc: 0.97665505\n",
      "val Loss: 1.06071850 Acc: 0.83248731\n",
      "\n",
      "Epoch 274/300\n",
      "----------\n",
      "train Loss: 0.07158769 Acc: 0.97386760\n",
      "val Loss: 1.04677154 Acc: 0.83248731\n",
      "\n",
      "Epoch 275/300\n",
      "----------\n",
      "train Loss: 0.06979462 Acc: 0.97351916\n",
      "val Loss: 1.11764578 Acc: 0.82487310\n",
      "\n",
      "Epoch 276/300\n",
      "----------\n",
      "train Loss: 0.06547816 Acc: 0.97421603\n",
      "val Loss: 1.06816777 Acc: 0.83502538\n",
      "\n",
      "Epoch 277/300\n",
      "----------\n",
      "train Loss: 0.06004601 Acc: 0.97909408\n",
      "val Loss: 1.07052778 Acc: 0.82994924\n",
      "\n",
      "Epoch 278/300\n",
      "----------\n",
      "train Loss: 0.05706346 Acc: 0.97839721\n",
      "val Loss: 1.06325622 Acc: 0.83248731\n",
      "\n",
      "Epoch 279/300\n",
      "----------\n",
      "train Loss: 0.06742840 Acc: 0.97595819\n",
      "val Loss: 1.06812910 Acc: 0.83248731\n",
      "\n",
      "Epoch 280/300\n",
      "----------\n",
      "train Loss: 0.05045090 Acc: 0.98118467\n",
      "val Loss: 1.04406090 Acc: 0.83502538\n",
      "\n",
      "Epoch 281/300\n",
      "----------\n",
      "train Loss: 0.06918545 Acc: 0.97351916\n",
      "val Loss: 1.13954456 Acc: 0.82487310\n",
      "\n",
      "Epoch 282/300\n",
      "----------\n",
      "train Loss: 0.06245799 Acc: 0.97770035\n",
      "val Loss: 1.09146000 Acc: 0.82741117\n",
      "\n",
      "Epoch 283/300\n",
      "----------\n",
      "train Loss: 0.06000396 Acc: 0.97700348\n",
      "val Loss: 1.07535533 Acc: 0.83502538\n",
      "\n",
      "Epoch 284/300\n",
      "----------\n",
      "train Loss: 0.06536016 Acc: 0.97351916\n",
      "val Loss: 1.07107868 Acc: 0.83248731\n",
      "\n",
      "Epoch 285/300\n",
      "----------\n",
      "train Loss: 0.06205173 Acc: 0.97526132\n",
      "val Loss: 1.04422136 Acc: 0.83502538\n",
      "\n",
      "Epoch 286/300\n",
      "----------\n",
      "train Loss: 0.06665012 Acc: 0.97421603\n",
      "val Loss: 1.07964947 Acc: 0.83248731\n",
      "\n",
      "Epoch 287/300\n",
      "----------\n",
      "train Loss: 0.06696052 Acc: 0.97630662\n",
      "val Loss: 1.12309662 Acc: 0.82487310\n",
      "\n",
      "Epoch 288/300\n",
      "----------\n",
      "train Loss: 0.06266490 Acc: 0.97804878\n",
      "val Loss: 1.06090582 Acc: 0.83502538\n",
      "\n",
      "Epoch 289/300\n",
      "----------\n",
      "train Loss: 0.05906107 Acc: 0.97804878\n",
      "val Loss: 1.06421873 Acc: 0.83502538\n",
      "\n",
      "Epoch 290/300\n",
      "----------\n",
      "train Loss: 0.07843091 Acc: 0.97282230\n",
      "val Loss: 1.03636450 Acc: 0.84010152\n",
      "\n",
      "Epoch 291/300\n",
      "----------\n",
      "train Loss: 0.06985510 Acc: 0.97456446\n",
      "val Loss: 1.06976931 Acc: 0.83248731\n",
      "\n",
      "Epoch 292/300\n",
      "----------\n",
      "train Loss: 0.06563728 Acc: 0.97038328\n",
      "val Loss: 1.00692216 Acc: 0.83248731\n",
      "\n",
      "Epoch 293/300\n",
      "----------\n",
      "train Loss: 0.05648221 Acc: 0.97944251\n",
      "val Loss: 1.04630744 Acc: 0.83248731\n",
      "\n",
      "Epoch 294/300\n",
      "----------\n",
      "train Loss: 0.06016621 Acc: 0.97804878\n",
      "val Loss: 1.07079900 Acc: 0.83502538\n",
      "\n",
      "Epoch 295/300\n",
      "----------\n",
      "train Loss: 0.06733009 Acc: 0.97317073\n",
      "val Loss: 1.09405912 Acc: 0.82741117\n",
      "\n",
      "Epoch 296/300\n",
      "----------\n",
      "train Loss: 0.05362602 Acc: 0.97944251\n",
      "val Loss: 1.03715865 Acc: 0.83756345\n",
      "\n",
      "Epoch 297/300\n",
      "----------\n",
      "train Loss: 0.06249810 Acc: 0.97421603\n",
      "val Loss: 1.06489287 Acc: 0.83248731\n",
      "\n",
      "Epoch 298/300\n",
      "----------\n",
      "train Loss: 0.06097716 Acc: 0.97421603\n",
      "val Loss: 1.03390964 Acc: 0.83248731\n",
      "\n",
      "Epoch 299/300\n",
      "----------\n",
      "train Loss: 0.06548116 Acc: 0.97595819\n",
      "val Loss: 1.03486883 Acc: 0.83756345\n",
      "\n",
      "Epoch 300/300\n",
      "----------\n",
      "train Loss: 0.06703239 Acc: 0.97560976\n",
      "val Loss: 1.05715864 Acc: 0.83248731\n",
      "\n",
      "Training complete in 61m 38s\n",
      "Best val Acc: 0.88071066 Best val loss: 0.71919305\n"
     ]
    }
   ],
   "source": [
    "CHECK_POINT_PATH = '/home/linh/Downloads/Brain/weights/EfficientNet_B0.pth'\n",
    "try:\n",
    "    checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "    print(\"checkpoint loaded\")\n",
    "except:\n",
    "    checkpoint = None\n",
    "    print(\"checkpoint not found\")\n",
    "if checkpoint == None:\n",
    "    CHECK_POINT_PATH = CHECK_POINT_PATH\n",
    "model, best_val_loss, best_val_acc = train_model(model,\n",
    "                                                 criterion,\n",
    "                                                 optimizer,\n",
    "                                                 scheduler,\n",
    "                                                 num_epochs = 300,\n",
    "                                                 checkpoint = None #torch.load(CHECK_POINT_PATH)\n",
    "                                                 ) \n",
    "                                                \n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, CHECK_POINT_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19_EfficientNet_B0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
