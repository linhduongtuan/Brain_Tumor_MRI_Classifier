{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40178,
     "status": "ok",
     "timestamp": 1588213047201,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "rPwL9bdoBNzQ",
    "outputId": "553f83f0-cbf1-48d5-a184-4f4c8ff055ac"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PIL\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from timm.data.mixup import *\n",
    "from datetime import datetime\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from timm.data.auto_augment import *\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "from timm.data.random_erasing import *\n",
    "#from pytorch_metric_learning import loss\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from timm.models.layers.activations import *\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from randaugment import RandAugment, ImageNetPolicy, Cutout\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179460,
     "status": "ok",
     "timestamp": 1588213186502,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "584ea32f-dbe1-4465-8e60-e0f4e5c96a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Glioma', 'Meningioma', 'No_Tumor', 'Pituitary']\n",
      "{'train': 2612, 'val': 652}\n",
      "cuda:1\n",
      "{0: 'Glioma', 1: 'Meningioma', 2: 'No_Tumor', 3: 'Pituitary'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([110, 3, 224, 224])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/home/linh/Downloads/Brain/'\n",
    "\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        ImageNetPolicy(),\n",
    "        Cutout(size=16),\n",
    "        #RandomErasing(),\n",
    "        #Mixup(),\n",
    "        #FastCollateMixup(Mixup),\n",
    "        #AugMixAugment(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "batch_size = 110\n",
    "data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4, pin_memory = True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)\n",
    "print(dataset_sizes)\n",
    "print(device)\n",
    "\n",
    "### we get the class_to_index in the data_Set but what we really need is the cat_to_names  so we will create\n",
    "_ = image_datasets['train'].class_to_idx\n",
    "cat_to_name = {_[i]: i for i in list(_.keys())}\n",
    "print(cat_to_name)\n",
    "    \n",
    "# Run this to test the data loader\n",
    "images, labels = next(iter(data_loader['val']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226470,
     "status": "ok",
     "timestamp": 1588213233519,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "N350JAHpu8c3",
    "outputId": "96a2d095-f78f-4ca5-eb0c-c5390e367831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def showimage(data_loader, number_images, cat_to_name):\\n    dataiter = iter(data_loader)\\n    images, labels = dataiter.next()\\n    images = images.numpy() # convert images to numpy for display\\n    # plot the images in the batch, along with the corresponding labels\\n    fig = plt.figure(figsize=(number_images, 4))\\n    for idx in np.arange(number_images):\\n        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\\n        img = np.transpose(images[idx])\\n        plt.imshow(img)\\n        ax.set_title(cat_to_name[labels.tolist()[idx]])\\n        \\n#### to show some  images\\nshowimage(data_loader['test'], 20, cat_to_name)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def showimage(data_loader, number_images, cat_to_name):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.numpy() # convert images to numpy for display\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(number_images, 4))\n",
    "    for idx in np.arange(number_images):\n",
    "        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\n",
    "        img = np.transpose(images[idx])\n",
    "        plt.imshow(img)\n",
    "        ax.set_title(cat_to_name[labels.tolist()[idx]])\n",
    "        \n",
    "#### to show some  images\n",
    "showimage(data_loader['test'], 20, cat_to_name)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226461,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "L9jdFtBjSAE6",
    "outputId": "f0f393c5-4369-422c-9aef-fc290ccc941d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=4, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = models.resnet50(pretrained=True)\n",
    "#model = timm.create_model('resnet50', pretrained=True)\n",
    "model = timm.create_model('efficientnet_b0', num_classes=4, pretrained=True)\n",
    "#model = timm.create_model('efficientnet_b0', num_classes=4, pretrained=True)\n",
    "#model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "\n",
    "\n",
    "#model.fc #show fully connected layer for ResNet family\n",
    "model.classifier #show the classifier layer (fully connected layer) for EfficientNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226454,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "6beb0600-5fdf-4ae6-a216-40c32a13bb9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters of the model is: 4012672\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# define `classifier` for ResNet\n",
    "# Otherwise, define `fc` for EfficientNet family \n",
    "#because the definition of the full connection/classifier of 2 CNN families is differnt\n",
    "'''fc = nn.Sequential(OrderedDict([#('fc1', nn.Linear(1280, 1000, bias=True)),\n",
    "                                 ('fc1', nn.Linear(2048, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, 4)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "# connect base model (EfficientNet_B0) with modified classifier layer\n",
    "model.fc = fc'''\n",
    "criterion = LabelSmoothingCrossEntropy()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Nadam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.01,momentum=0.9,\n",
    "                      nesterov=True,\n",
    "                      weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "#lr = lambda x: (((1 + math.cos(x * math.pi / num_epochs)) / 2) ** 1) * 0.9\n",
    "#scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr)\n",
    "#show our model architechture and send to GPU\n",
    "model.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(\"The number of parameters of the model is:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPNx-TodPpVA"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=200, checkpoint = None):\n",
    "    since = time.time()\n",
    "\n",
    "    if checkpoint is None:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = math.inf\n",
    "        best_acc = 0.\n",
    "    else:\n",
    "        print(f'Val loss: {checkpoint[\"best_val_loss\"]}, Val accuracy: {checkpoint[\"best_val_accuracy\"]}')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "   \n",
    "    # Tensorboard summary\n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch +1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(data_loader[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if i % 1000 == 999:\n",
    "                    print('[%d, %d] loss: %.8f' % \n",
    "                          (epoch + 1, i, running_loss / (i * inputs.size(0))))\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':                \n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.8f} Acc: {:.8f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # Record training loss and accuracy for each phase\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Train/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            else:\n",
    "                writer.add_scalar('Valid/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Valid/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            # deep copy the model\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                print(f'New best model found!')\n",
    "                print(f'New record ACC: {epoch_acc}, previous record acc: {best_acc}')\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'best_val_loss': best_loss,\n",
    "                            'best_val_accuracy': best_acc,\n",
    "                            'scheduler_state_dict' : scheduler.state_dict(),\n",
    "                            }, \n",
    "                            CHECK_POINT_PATH\n",
    "                            )\n",
    "                print(f'New record acc is SAVED: {epoch_acc}')\n",
    "\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.8f} Best val loss: {:.8f}'.format(best_acc, best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vcXkJFOlP4NJ",
    "outputId": "e47fadb8-c292-4051-8a56-bbdc5868abe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint not found\n",
      "Epoch 1/300\n",
      "----------\n",
      "train Loss: 2.14023827 Acc: 0.50421133\n",
      "val Loss: 1.75760119 Acc: 0.65950920\n",
      "New best model found!\n",
      "New record ACC: 0.6595092024539877, previous record acc: 0.0\n",
      "New record acc is SAVED: 0.6595092024539877\n",
      "\n",
      "Epoch 2/300\n",
      "----------\n",
      "train Loss: 1.26793926 Acc: 0.60260337\n",
      "val Loss: 1.07298842 Acc: 0.68558282\n",
      "New best model found!\n",
      "New record ACC: 0.6855828220858896, previous record acc: 0.6595092024539877\n",
      "New record acc is SAVED: 0.6855828220858896\n",
      "\n",
      "Epoch 3/300\n",
      "----------\n",
      "train Loss: 1.00936887 Acc: 0.67036753\n",
      "val Loss: 0.79346804 Acc: 0.80981595\n",
      "New best model found!\n",
      "New record ACC: 0.8098159509202454, previous record acc: 0.6855828220858896\n",
      "New record acc is SAVED: 0.8098159509202454\n",
      "\n",
      "Epoch 4/300\n",
      "----------\n",
      "train Loss: 0.88068805 Acc: 0.73162328\n",
      "val Loss: 0.71065354 Acc: 0.85736196\n",
      "New best model found!\n",
      "New record ACC: 0.8573619631901841, previous record acc: 0.8098159509202454\n",
      "New record acc is SAVED: 0.8573619631901841\n",
      "\n",
      "Epoch 5/300\n",
      "----------\n",
      "train Loss: 0.82845375 Acc: 0.75459418\n",
      "val Loss: 0.65826084 Acc: 0.87116564\n",
      "New best model found!\n",
      "New record ACC: 0.8711656441717791, previous record acc: 0.8573619631901841\n",
      "New record acc is SAVED: 0.8711656441717791\n",
      "\n",
      "Epoch 6/300\n",
      "----------\n",
      "train Loss: 0.79163745 Acc: 0.77488515\n",
      "val Loss: 0.62795784 Acc: 0.87423313\n",
      "New best model found!\n",
      "New record ACC: 0.8742331288343559, previous record acc: 0.8711656441717791\n",
      "New record acc is SAVED: 0.8742331288343559\n",
      "\n",
      "Epoch 7/300\n",
      "----------\n",
      "train Loss: 0.74438527 Acc: 0.80130168\n",
      "val Loss: 0.64221431 Acc: 0.86196319\n",
      "\n",
      "Epoch 8/300\n",
      "----------\n",
      "train Loss: 0.72431716 Acc: 0.81661562\n",
      "val Loss: 0.56371524 Acc: 0.90184049\n",
      "New best model found!\n",
      "New record ACC: 0.901840490797546, previous record acc: 0.8742331288343559\n",
      "New record acc is SAVED: 0.901840490797546\n",
      "\n",
      "Epoch 9/300\n",
      "----------\n",
      "train Loss: 0.71773778 Acc: 0.81584992\n",
      "val Loss: 0.57086986 Acc: 0.90797546\n",
      "New best model found!\n",
      "New record ACC: 0.9079754601226994, previous record acc: 0.901840490797546\n",
      "New record acc is SAVED: 0.9079754601226994\n",
      "\n",
      "Epoch 10/300\n",
      "----------\n",
      "train Loss: 0.68782151 Acc: 0.82886677\n",
      "val Loss: 0.53507332 Acc: 0.93251534\n",
      "New best model found!\n",
      "New record ACC: 0.9325153374233129, previous record acc: 0.9079754601226994\n",
      "New record acc is SAVED: 0.9325153374233129\n",
      "\n",
      "Epoch 11/300\n",
      "----------\n",
      "train Loss: 0.67173156 Acc: 0.84303216\n",
      "val Loss: 0.53830285 Acc: 0.92638037\n",
      "\n",
      "Epoch 12/300\n",
      "----------\n",
      "train Loss: 0.66745191 Acc: 0.84264931\n",
      "val Loss: 0.51340997 Acc: 0.94478528\n",
      "New best model found!\n",
      "New record ACC: 0.9447852760736196, previous record acc: 0.9325153374233129\n",
      "New record acc is SAVED: 0.9447852760736196\n",
      "\n",
      "Epoch 13/300\n",
      "----------\n",
      "train Loss: 0.63532360 Acc: 0.86370597\n",
      "val Loss: 0.51920248 Acc: 0.93404908\n",
      "\n",
      "Epoch 14/300\n",
      "----------\n",
      "train Loss: 0.63948270 Acc: 0.85183767\n",
      "val Loss: 0.51453006 Acc: 0.94171779\n",
      "\n",
      "Epoch 15/300\n",
      "----------\n",
      "train Loss: 0.63482912 Acc: 0.86102603\n",
      "val Loss: 0.51808821 Acc: 0.93251534\n",
      "\n",
      "Epoch 16/300\n",
      "----------\n",
      "train Loss: 0.62960670 Acc: 0.86523737\n",
      "val Loss: 0.51595098 Acc: 0.93251534\n",
      "\n",
      "Epoch 17/300\n",
      "----------\n",
      "train Loss: 0.62260952 Acc: 0.86944870\n",
      "val Loss: 0.50676767 Acc: 0.94018405\n",
      "\n",
      "Epoch 18/300\n",
      "----------\n",
      "train Loss: 0.62146536 Acc: 0.86715161\n",
      "val Loss: 0.51483738 Acc: 0.93865031\n",
      "\n",
      "Epoch 19/300\n",
      "----------\n",
      "train Loss: 0.60549004 Acc: 0.87557427\n",
      "val Loss: 0.48475835 Acc: 0.94631902\n",
      "New best model found!\n",
      "New record ACC: 0.946319018404908, previous record acc: 0.9447852760736196\n",
      "New record acc is SAVED: 0.946319018404908\n",
      "\n",
      "Epoch 20/300\n",
      "----------\n",
      "train Loss: 0.60149367 Acc: 0.87787136\n",
      "val Loss: 0.48122474 Acc: 0.95398773\n",
      "New best model found!\n",
      "New record ACC: 0.9539877300613497, previous record acc: 0.946319018404908\n",
      "New record acc is SAVED: 0.9539877300613497\n",
      "\n",
      "Epoch 21/300\n",
      "----------\n",
      "train Loss: 0.58923053 Acc: 0.88629403\n",
      "val Loss: 0.47714041 Acc: 0.95705521\n",
      "New best model found!\n",
      "New record ACC: 0.9570552147239264, previous record acc: 0.9539877300613497\n",
      "New record acc is SAVED: 0.9570552147239264\n",
      "\n",
      "Epoch 22/300\n",
      "----------\n",
      "train Loss: 0.58380137 Acc: 0.89548239\n",
      "val Loss: 0.47898047 Acc: 0.95245399\n",
      "\n",
      "Epoch 23/300\n",
      "----------\n",
      "train Loss: 0.59057389 Acc: 0.88361409\n",
      "val Loss: 0.48024590 Acc: 0.95245399\n",
      "\n",
      "Epoch 24/300\n",
      "----------\n",
      "train Loss: 0.57430450 Acc: 0.88705972\n",
      "val Loss: 0.48540169 Acc: 0.94938650\n",
      "\n",
      "Epoch 25/300\n",
      "----------\n",
      "train Loss: 0.58063665 Acc: 0.89509954\n",
      "val Loss: 0.45725307 Acc: 0.97546012\n",
      "New best model found!\n",
      "New record ACC: 0.9754601226993865, previous record acc: 0.9570552147239264\n",
      "New record acc is SAVED: 0.9754601226993865\n",
      "\n",
      "Epoch 26/300\n",
      "----------\n",
      "train Loss: 0.57421872 Acc: 0.89356815\n",
      "val Loss: 0.46497525 Acc: 0.96319018\n",
      "\n",
      "Epoch 27/300\n",
      "----------\n",
      "train Loss: 0.55520058 Acc: 0.90849923\n",
      "val Loss: 0.46046175 Acc: 0.96165644\n",
      "\n",
      "Epoch 28/300\n",
      "----------\n",
      "train Loss: 0.56170294 Acc: 0.90237366\n",
      "val Loss: 0.46158880 Acc: 0.95245399\n",
      "\n",
      "Epoch 29/300\n",
      "----------\n",
      "train Loss: 0.56511680 Acc: 0.89663093\n",
      "val Loss: 0.46069922 Acc: 0.96165644\n",
      "\n",
      "Epoch 30/300\n",
      "----------\n",
      "train Loss: 0.55395866 Acc: 0.90581930\n",
      "val Loss: 0.45549359 Acc: 0.96319018\n",
      "\n",
      "Epoch 31/300\n",
      "----------\n",
      "train Loss: 0.54612412 Acc: 0.90275651\n",
      "val Loss: 0.45301069 Acc: 0.96319018\n",
      "\n",
      "Epoch 32/300\n",
      "----------\n",
      "train Loss: 0.53780274 Acc: 0.91156202\n",
      "val Loss: 0.45016823 Acc: 0.96472393\n",
      "\n",
      "Epoch 33/300\n",
      "----------\n",
      "train Loss: 0.53856852 Acc: 0.91615620\n",
      "val Loss: 0.45172202 Acc: 0.96625767\n",
      "\n",
      "Epoch 34/300\n",
      "----------\n",
      "train Loss: 0.54031620 Acc: 0.91653905\n",
      "val Loss: 0.46409707 Acc: 0.96165644\n",
      "\n",
      "Epoch 35/300\n",
      "----------\n",
      "train Loss: 0.53536292 Acc: 0.91539051\n",
      "val Loss: 0.44304509 Acc: 0.96932515\n",
      "\n",
      "Epoch 36/300\n",
      "----------\n",
      "train Loss: 0.53733977 Acc: 0.91500766\n",
      "val Loss: 0.44475009 Acc: 0.96625767\n",
      "\n",
      "Epoch 37/300\n",
      "----------\n",
      "train Loss: 0.52882766 Acc: 0.91768760\n",
      "val Loss: 0.43935918 Acc: 0.96625767\n",
      "\n",
      "Epoch 38/300\n",
      "----------\n",
      "train Loss: 0.52418117 Acc: 0.91730475\n",
      "val Loss: 0.44639513 Acc: 0.96779141\n",
      "\n",
      "Epoch 39/300\n",
      "----------\n",
      "train Loss: 0.52367516 Acc: 0.91768760\n",
      "val Loss: 0.44200366 Acc: 0.96625767\n",
      "\n",
      "Epoch 40/300\n",
      "----------\n",
      "train Loss: 0.51766989 Acc: 0.92764165\n",
      "val Loss: 0.44695844 Acc: 0.96625767\n",
      "\n",
      "Epoch 41/300\n",
      "----------\n",
      "train Loss: 0.53051387 Acc: 0.91921899\n",
      "val Loss: 0.44298704 Acc: 0.96779141\n",
      "\n",
      "Epoch 42/300\n",
      "----------\n",
      "train Loss: 0.51804892 Acc: 0.92611026\n",
      "val Loss: 0.45194635 Acc: 0.96165644\n",
      "\n",
      "Epoch 43/300\n",
      "----------\n",
      "train Loss: 0.52233099 Acc: 0.92151608\n",
      "val Loss: 0.43845008 Acc: 0.97392638\n",
      "\n",
      "Epoch 44/300\n",
      "----------\n",
      "train Loss: 0.51645192 Acc: 0.92304747\n",
      "val Loss: 0.44280470 Acc: 0.97392638\n",
      "\n",
      "Epoch 45/300\n",
      "----------\n",
      "train Loss: 0.50664624 Acc: 0.93032159\n",
      "val Loss: 0.44156597 Acc: 0.97085890\n",
      "\n",
      "Epoch 46/300\n",
      "----------\n",
      "train Loss: 0.51501473 Acc: 0.92611026\n",
      "val Loss: 0.43867323 Acc: 0.96472393\n",
      "\n",
      "Epoch 47/300\n",
      "----------\n",
      "train Loss: 0.50194250 Acc: 0.93223583\n",
      "val Loss: 0.43517275 Acc: 0.97239264\n",
      "\n",
      "Epoch 48/300\n",
      "----------\n",
      "train Loss: 0.49750167 Acc: 0.93070444\n",
      "val Loss: 0.44095702 Acc: 0.97085890\n",
      "\n",
      "Epoch 49/300\n",
      "----------\n",
      "train Loss: 0.49851075 Acc: 0.93606432\n",
      "val Loss: 0.43482933 Acc: 0.96932515\n",
      "\n",
      "Epoch 50/300\n",
      "----------\n",
      "train Loss: 0.50589284 Acc: 0.92266462\n",
      "val Loss: 0.42704795 Acc: 0.97392638\n",
      "\n",
      "Epoch 51/300\n",
      "----------\n",
      "train Loss: 0.48673495 Acc: 0.94180704\n",
      "val Loss: 0.43122328 Acc: 0.96932515\n",
      "\n",
      "Epoch 52/300\n",
      "----------\n",
      "train Loss: 0.49912679 Acc: 0.93147014\n",
      "val Loss: 0.43997650 Acc: 0.96932515\n",
      "\n",
      "Epoch 53/300\n",
      "----------\n",
      "train Loss: 0.49012619 Acc: 0.93453292\n",
      "val Loss: 0.43772721 Acc: 0.96779141\n",
      "\n",
      "Epoch 54/300\n",
      "----------\n",
      "train Loss: 0.48891483 Acc: 0.93759571\n",
      "val Loss: 0.42942589 Acc: 0.97239264\n",
      "\n",
      "Epoch 55/300\n",
      "----------\n",
      "train Loss: 0.49818056 Acc: 0.93568147\n",
      "val Loss: 0.42809371 Acc: 0.97085890\n",
      "\n",
      "Epoch 56/300\n",
      "----------\n",
      "train Loss: 0.49561698 Acc: 0.93147014\n",
      "val Loss: 0.42719271 Acc: 0.97392638\n",
      "\n",
      "Epoch 57/300\n",
      "----------\n",
      "train Loss: 0.48849383 Acc: 0.93759571\n",
      "val Loss: 0.42724720 Acc: 0.97392638\n",
      "\n",
      "Epoch 58/300\n",
      "----------\n",
      "train Loss: 0.47663883 Acc: 0.94716692\n",
      "val Loss: 0.42871148 Acc: 0.97239264\n",
      "\n",
      "Epoch 59/300\n",
      "----------\n",
      "train Loss: 0.49350939 Acc: 0.93376723\n",
      "val Loss: 0.42725473 Acc: 0.97699387\n",
      "New best model found!\n",
      "New record ACC: 0.9769938650306749, previous record acc: 0.9754601226993865\n",
      "New record acc is SAVED: 0.9769938650306749\n",
      "\n",
      "Epoch 60/300\n",
      "----------\n",
      "train Loss: 0.48717663 Acc: 0.94180704\n",
      "val Loss: 0.42244564 Acc: 0.97852761\n",
      "New best model found!\n",
      "New record ACC: 0.9785276073619632, previous record acc: 0.9769938650306749\n",
      "New record acc is SAVED: 0.9785276073619632\n",
      "\n",
      "Epoch 61/300\n",
      "----------\n",
      "train Loss: 0.48358272 Acc: 0.94257274\n",
      "val Loss: 0.42394511 Acc: 0.97546012\n",
      "\n",
      "Epoch 62/300\n",
      "----------\n",
      "train Loss: 0.48063370 Acc: 0.94754977\n",
      "val Loss: 0.43088212 Acc: 0.97085890\n",
      "\n",
      "Epoch 63/300\n",
      "----------\n",
      "train Loss: 0.48161490 Acc: 0.94372129\n",
      "val Loss: 0.42211465 Acc: 0.97546012\n",
      "\n",
      "Epoch 64/300\n",
      "----------\n",
      "train Loss: 0.48860380 Acc: 0.93568147\n",
      "val Loss: 0.41878023 Acc: 0.97699387\n",
      "\n",
      "Epoch 65/300\n",
      "----------\n",
      "train Loss: 0.48336147 Acc: 0.93989280\n",
      "val Loss: 0.41906825 Acc: 0.97392638\n",
      "\n",
      "Epoch 66/300\n",
      "----------\n",
      "train Loss: 0.46966152 Acc: 0.94984686\n",
      "val Loss: 0.41811068 Acc: 0.97699387\n",
      "\n",
      "Epoch 67/300\n",
      "----------\n",
      "train Loss: 0.47887318 Acc: 0.94601838\n",
      "val Loss: 0.41690019 Acc: 0.97852761\n",
      "\n",
      "Epoch 68/300\n",
      "----------\n",
      "train Loss: 0.47626480 Acc: 0.94410413\n",
      "val Loss: 0.41356310 Acc: 0.97239264\n",
      "\n",
      "Epoch 69/300\n",
      "----------\n",
      "train Loss: 0.48168760 Acc: 0.94218989\n",
      "val Loss: 0.41790858 Acc: 0.97392638\n",
      "\n",
      "Epoch 70/300\n",
      "----------\n",
      "train Loss: 0.45823884 Acc: 0.95558959\n",
      "val Loss: 0.41298384 Acc: 0.97699387\n",
      "\n",
      "Epoch 71/300\n",
      "----------\n",
      "train Loss: 0.47366232 Acc: 0.94525268\n",
      "val Loss: 0.41768020 Acc: 0.97546012\n",
      "\n",
      "Epoch 72/300\n",
      "----------\n",
      "train Loss: 0.46396632 Acc: 0.94946401\n",
      "val Loss: 0.41818381 Acc: 0.97392638\n",
      "\n",
      "Epoch 73/300\n",
      "----------\n",
      "train Loss: 0.47224724 Acc: 0.94678407\n",
      "val Loss: 0.42158191 Acc: 0.97852761\n",
      "\n",
      "Epoch 74/300\n",
      "----------\n",
      "train Loss: 0.46963903 Acc: 0.94793262\n",
      "val Loss: 0.41292542 Acc: 0.97546012\n",
      "\n",
      "Epoch 75/300\n",
      "----------\n",
      "train Loss: 0.46793487 Acc: 0.94525268\n",
      "val Loss: 0.41446834 Acc: 0.97392638\n",
      "\n",
      "Epoch 76/300\n",
      "----------\n",
      "train Loss: 0.46427698 Acc: 0.94754977\n",
      "val Loss: 0.40957172 Acc: 0.97699387\n",
      "\n",
      "Epoch 77/300\n",
      "----------\n",
      "train Loss: 0.46480006 Acc: 0.94946401\n",
      "val Loss: 0.40858840 Acc: 0.97546012\n",
      "\n",
      "Epoch 78/300\n",
      "----------\n",
      "train Loss: 0.46917481 Acc: 0.94908116\n",
      "val Loss: 0.40762512 Acc: 0.97546012\n",
      "\n",
      "Epoch 79/300\n",
      "----------\n",
      "train Loss: 0.46363571 Acc: 0.95022971\n",
      "val Loss: 0.40731862 Acc: 0.97699387\n",
      "\n",
      "Epoch 80/300\n",
      "----------\n",
      "train Loss: 0.47059955 Acc: 0.94754977\n",
      "val Loss: 0.40715903 Acc: 0.98006135\n",
      "New best model found!\n",
      "New record ACC: 0.9800613496932515, previous record acc: 0.9785276073619632\n",
      "New record acc is SAVED: 0.9800613496932515\n",
      "\n",
      "Epoch 81/300\n",
      "----------\n",
      "train Loss: 0.45858314 Acc: 0.95061256\n",
      "val Loss: 0.40974197 Acc: 0.97546012\n",
      "\n",
      "Epoch 82/300\n",
      "----------\n",
      "train Loss: 0.44966547 Acc: 0.95750383\n",
      "val Loss: 0.40938363 Acc: 0.97699387\n",
      "\n",
      "Epoch 83/300\n",
      "----------\n",
      "train Loss: 0.46740954 Acc: 0.94831547\n",
      "val Loss: 0.41037297 Acc: 0.97699387\n",
      "\n",
      "Epoch 84/300\n",
      "----------\n",
      "train Loss: 0.46071143 Acc: 0.95558959\n",
      "val Loss: 0.41014346 Acc: 0.97546012\n",
      "\n",
      "Epoch 85/300\n",
      "----------\n",
      "train Loss: 0.46243049 Acc: 0.94333844\n",
      "val Loss: 0.41161639 Acc: 0.97546012\n",
      "\n",
      "Epoch 86/300\n",
      "----------\n",
      "train Loss: 0.46143842 Acc: 0.95137825\n",
      "val Loss: 0.41077653 Acc: 0.97852761\n",
      "\n",
      "Epoch 87/300\n",
      "----------\n",
      "train Loss: 0.46510572 Acc: 0.94831547\n",
      "val Loss: 0.40835095 Acc: 0.97392638\n",
      "\n",
      "Epoch 88/300\n",
      "----------\n",
      "train Loss: 0.44718593 Acc: 0.95444104\n",
      "val Loss: 0.41126840 Acc: 0.97392638\n",
      "\n",
      "Epoch 89/300\n",
      "----------\n",
      "train Loss: 0.45806844 Acc: 0.95214395\n",
      "val Loss: 0.41525218 Acc: 0.97392638\n",
      "\n",
      "Epoch 90/300\n",
      "----------\n",
      "train Loss: 0.45538816 Acc: 0.95137825\n",
      "val Loss: 0.41398829 Acc: 0.97546012\n",
      "\n",
      "Epoch 91/300\n",
      "----------\n",
      "train Loss: 0.45690496 Acc: 0.95252680\n",
      "val Loss: 0.41099699 Acc: 0.97699387\n",
      "\n",
      "Epoch 92/300\n",
      "----------\n",
      "train Loss: 0.46041581 Acc: 0.95329250\n",
      "val Loss: 0.40483645 Acc: 0.97852761\n",
      "\n",
      "Epoch 93/300\n",
      "----------\n",
      "train Loss: 0.45896876 Acc: 0.94754977\n",
      "val Loss: 0.40778425 Acc: 0.98006135\n",
      "\n",
      "Epoch 94/300\n",
      "----------\n",
      "train Loss: 0.45688151 Acc: 0.95788668\n",
      "val Loss: 0.40704499 Acc: 0.97699387\n",
      "\n",
      "Epoch 95/300\n",
      "----------\n",
      "train Loss: 0.44219254 Acc: 0.96171516\n",
      "val Loss: 0.40299309 Acc: 0.97852761\n",
      "\n",
      "Epoch 96/300\n",
      "----------\n",
      "train Loss: 0.45098713 Acc: 0.95214395\n",
      "val Loss: 0.40526529 Acc: 0.97852761\n",
      "\n",
      "Epoch 97/300\n",
      "----------\n",
      "train Loss: 0.45370028 Acc: 0.95367534\n",
      "val Loss: 0.40295759 Acc: 0.97699387\n",
      "\n",
      "Epoch 98/300\n",
      "----------\n",
      "train Loss: 0.44942452 Acc: 0.95597243\n",
      "val Loss: 0.40712516 Acc: 0.97546012\n",
      "\n",
      "Epoch 99/300\n",
      "----------\n",
      "train Loss: 0.45011217 Acc: 0.95558959\n",
      "val Loss: 0.40716930 Acc: 0.97392638\n",
      "\n",
      "Epoch 100/300\n",
      "----------\n",
      "train Loss: 0.44953609 Acc: 0.95405819\n",
      "val Loss: 0.40758215 Acc: 0.98006135\n",
      "\n",
      "Epoch 101/300\n",
      "----------\n",
      "train Loss: 0.44518561 Acc: 0.96056662\n",
      "val Loss: 0.40527562 Acc: 0.97546012\n",
      "\n",
      "Epoch 102/300\n",
      "----------\n",
      "train Loss: 0.45936648 Acc: 0.95290965\n",
      "val Loss: 0.40356301 Acc: 0.97546012\n",
      "\n",
      "Epoch 103/300\n",
      "----------\n",
      "train Loss: 0.45033003 Acc: 0.95750383\n",
      "val Loss: 0.40278926 Acc: 0.97699387\n",
      "\n",
      "Epoch 104/300\n",
      "----------\n",
      "train Loss: 0.44430525 Acc: 0.95444104\n",
      "val Loss: 0.40213154 Acc: 0.97852761\n",
      "\n",
      "Epoch 105/300\n",
      "----------\n",
      "train Loss: 0.44206628 Acc: 0.96286371\n",
      "val Loss: 0.40344509 Acc: 0.97699387\n",
      "\n",
      "Epoch 106/300\n",
      "----------\n",
      "train Loss: 0.44878243 Acc: 0.95597243\n",
      "val Loss: 0.40285223 Acc: 0.97546012\n",
      "\n",
      "Epoch 107/300\n",
      "----------\n",
      "train Loss: 0.44326555 Acc: 0.95980092\n",
      "val Loss: 0.40247389 Acc: 0.97852761\n",
      "\n",
      "Epoch 108/300\n",
      "----------\n",
      "train Loss: 0.44298320 Acc: 0.96094946\n",
      "val Loss: 0.40175995 Acc: 0.97699387\n",
      "\n",
      "Epoch 109/300\n",
      "----------\n",
      "train Loss: 0.43985403 Acc: 0.96094946\n",
      "val Loss: 0.40262523 Acc: 0.97699387\n",
      "\n",
      "Epoch 110/300\n",
      "----------\n",
      "train Loss: 0.45266342 Acc: 0.95290965\n",
      "val Loss: 0.40289148 Acc: 0.97699387\n",
      "\n",
      "Epoch 111/300\n",
      "----------\n",
      "train Loss: 0.44780473 Acc: 0.95520674\n",
      "val Loss: 0.40205887 Acc: 0.97852761\n",
      "\n",
      "Epoch 112/300\n",
      "----------\n",
      "train Loss: 0.44176947 Acc: 0.96209801\n",
      "val Loss: 0.40101790 Acc: 0.97852761\n",
      "\n",
      "Epoch 113/300\n",
      "----------\n",
      "train Loss: 0.44105111 Acc: 0.96056662\n",
      "val Loss: 0.40166266 Acc: 0.97852761\n",
      "\n",
      "Epoch 114/300\n",
      "----------\n",
      "train Loss: 0.45058439 Acc: 0.95367534\n",
      "val Loss: 0.40289260 Acc: 0.97852761\n",
      "\n",
      "Epoch 115/300\n",
      "----------\n",
      "train Loss: 0.44120518 Acc: 0.96171516\n",
      "val Loss: 0.40090532 Acc: 0.97699387\n",
      "\n",
      "Epoch 116/300\n",
      "----------\n",
      "train Loss: 0.44156775 Acc: 0.95673813\n",
      "val Loss: 0.40144736 Acc: 0.97852761\n",
      "\n",
      "Epoch 117/300\n",
      "----------\n",
      "train Loss: 0.43803034 Acc: 0.96286371\n",
      "val Loss: 0.40190119 Acc: 0.97852761\n",
      "\n",
      "Epoch 118/300\n",
      "----------\n",
      "train Loss: 0.44524870 Acc: 0.96018377\n",
      "val Loss: 0.40180800 Acc: 0.97852761\n",
      "\n",
      "Epoch 119/300\n",
      "----------\n",
      "train Loss: 0.43997114 Acc: 0.96171516\n",
      "val Loss: 0.40159490 Acc: 0.98006135\n",
      "\n",
      "Epoch 120/300\n",
      "----------\n",
      "train Loss: 0.43279735 Acc: 0.96516080\n",
      "val Loss: 0.40247698 Acc: 0.98006135\n",
      "\n",
      "Epoch 121/300\n",
      "----------\n",
      "train Loss: 0.44052944 Acc: 0.95826953\n",
      "val Loss: 0.40334240 Acc: 0.97852761\n",
      "\n",
      "Epoch 122/300\n",
      "----------\n",
      "train Loss: 0.43873907 Acc: 0.96362940\n",
      "val Loss: 0.40218901 Acc: 0.97852761\n",
      "\n",
      "Epoch 123/300\n",
      "----------\n",
      "train Loss: 0.44541330 Acc: 0.95980092\n",
      "val Loss: 0.40277629 Acc: 0.97852761\n",
      "\n",
      "Epoch 124/300\n",
      "----------\n",
      "train Loss: 0.43826081 Acc: 0.96094946\n",
      "val Loss: 0.40236545 Acc: 0.97852761\n",
      "\n",
      "Epoch 125/300\n",
      "----------\n",
      "train Loss: 0.43804489 Acc: 0.95635528\n",
      "val Loss: 0.40244280 Acc: 0.97852761\n",
      "\n",
      "Epoch 126/300\n",
      "----------\n",
      "train Loss: 0.44241056 Acc: 0.96133231\n",
      "val Loss: 0.40155082 Acc: 0.98006135\n",
      "\n",
      "Epoch 127/300\n",
      "----------\n",
      "train Loss: 0.42924780 Acc: 0.96937213\n",
      "val Loss: 0.40101605 Acc: 0.97852761\n",
      "\n",
      "Epoch 128/300\n",
      "----------\n",
      "train Loss: 0.44157103 Acc: 0.96056662\n",
      "val Loss: 0.40108918 Acc: 0.97852761\n",
      "\n",
      "Epoch 129/300\n",
      "----------\n",
      "train Loss: 0.43513823 Acc: 0.96171516\n",
      "val Loss: 0.40058710 Acc: 0.97699387\n",
      "\n",
      "Epoch 130/300\n",
      "----------\n",
      "train Loss: 0.44352293 Acc: 0.95750383\n",
      "val Loss: 0.40179770 Acc: 0.97852761\n",
      "\n",
      "Epoch 131/300\n",
      "----------\n",
      "train Loss: 0.43076159 Acc: 0.96630934\n",
      "val Loss: 0.40109601 Acc: 0.97852761\n",
      "\n",
      "Epoch 132/300\n",
      "----------\n",
      "train Loss: 0.44898293 Acc: 0.95597243\n",
      "val Loss: 0.40175353 Acc: 0.98006135\n",
      "\n",
      "Epoch 133/300\n",
      "----------\n",
      "train Loss: 0.44222301 Acc: 0.95750383\n",
      "val Loss: 0.40018370 Acc: 0.97852761\n",
      "\n",
      "Epoch 134/300\n",
      "----------\n",
      "train Loss: 0.44304144 Acc: 0.95673813\n",
      "val Loss: 0.40119755 Acc: 0.97699387\n",
      "\n",
      "Epoch 135/300\n",
      "----------\n",
      "train Loss: 0.43927192 Acc: 0.96324655\n",
      "val Loss: 0.40102523 Acc: 0.97852761\n",
      "\n",
      "Epoch 136/300\n",
      "----------\n",
      "train Loss: 0.44230123 Acc: 0.96094946\n",
      "val Loss: 0.40143555 Acc: 0.97546012\n",
      "\n",
      "Epoch 137/300\n",
      "----------\n",
      "train Loss: 0.44125814 Acc: 0.95980092\n",
      "val Loss: 0.40041395 Acc: 0.97699387\n",
      "\n",
      "Epoch 138/300\n",
      "----------\n",
      "train Loss: 0.43707202 Acc: 0.96248086\n",
      "val Loss: 0.40223685 Acc: 0.97546012\n",
      "\n",
      "Epoch 139/300\n",
      "----------\n",
      "train Loss: 0.43789081 Acc: 0.96171516\n",
      "val Loss: 0.40125475 Acc: 0.97546012\n",
      "\n",
      "Epoch 140/300\n",
      "----------\n",
      "train Loss: 0.43864400 Acc: 0.96171516\n",
      "val Loss: 0.40113007 Acc: 0.97546012\n",
      "\n",
      "Epoch 141/300\n",
      "----------\n",
      "train Loss: 0.44270548 Acc: 0.96056662\n",
      "val Loss: 0.40034321 Acc: 0.97546012\n",
      "\n",
      "Epoch 142/300\n",
      "----------\n",
      "train Loss: 0.44191958 Acc: 0.95788668\n",
      "val Loss: 0.40081453 Acc: 0.97852761\n",
      "\n",
      "Epoch 143/300\n",
      "----------\n",
      "train Loss: 0.42848995 Acc: 0.96898928\n",
      "val Loss: 0.40163999 Acc: 0.97546012\n",
      "\n",
      "Epoch 144/300\n",
      "----------\n",
      "train Loss: 0.44774055 Acc: 0.95597243\n",
      "val Loss: 0.40168607 Acc: 0.97699387\n",
      "\n",
      "Epoch 145/300\n",
      "----------\n",
      "train Loss: 0.44417336 Acc: 0.95712098\n",
      "val Loss: 0.40069887 Acc: 0.97699387\n",
      "\n",
      "Epoch 146/300\n",
      "----------\n",
      "train Loss: 0.43856018 Acc: 0.95941807\n",
      "val Loss: 0.40081251 Acc: 0.97852761\n",
      "\n",
      "Epoch 147/300\n",
      "----------\n",
      "train Loss: 0.43592704 Acc: 0.96286371\n",
      "val Loss: 0.40038132 Acc: 0.97699387\n",
      "\n",
      "Epoch 148/300\n",
      "----------\n",
      "train Loss: 0.44391165 Acc: 0.96171516\n",
      "val Loss: 0.40088815 Acc: 0.97546012\n",
      "\n",
      "Epoch 149/300\n",
      "----------\n",
      "train Loss: 0.44461463 Acc: 0.95712098\n",
      "val Loss: 0.40000535 Acc: 0.97546012\n",
      "\n",
      "Epoch 150/300\n",
      "----------\n",
      "train Loss: 0.44112542 Acc: 0.96018377\n",
      "val Loss: 0.40088520 Acc: 0.97852761\n",
      "\n",
      "Epoch 151/300\n",
      "----------\n",
      "train Loss: 0.43755661 Acc: 0.96171516\n",
      "val Loss: 0.40084870 Acc: 0.97546012\n",
      "\n",
      "Epoch 152/300\n",
      "----------\n",
      "train Loss: 0.43650514 Acc: 0.96401225\n",
      "val Loss: 0.40110566 Acc: 0.97546012\n",
      "\n",
      "Epoch 153/300\n",
      "----------\n",
      "train Loss: 0.44380192 Acc: 0.96018377\n",
      "val Loss: 0.40223893 Acc: 0.97699387\n",
      "\n",
      "Epoch 154/300\n",
      "----------\n",
      "train Loss: 0.43888287 Acc: 0.95712098\n",
      "val Loss: 0.40159511 Acc: 0.97699387\n",
      "\n",
      "Epoch 155/300\n",
      "----------\n",
      "train Loss: 0.44027880 Acc: 0.96362940\n",
      "val Loss: 0.39991692 Acc: 0.97699387\n",
      "\n",
      "Epoch 156/300\n",
      "----------\n",
      "train Loss: 0.43224289 Acc: 0.96630934\n",
      "val Loss: 0.40139904 Acc: 0.98006135\n",
      "\n",
      "Epoch 157/300\n",
      "----------\n",
      "train Loss: 0.43646051 Acc: 0.96477795\n",
      "val Loss: 0.40084026 Acc: 0.97392638\n",
      "\n",
      "Epoch 158/300\n",
      "----------\n",
      "train Loss: 0.44113466 Acc: 0.96056662\n",
      "val Loss: 0.40102450 Acc: 0.97852761\n",
      "\n",
      "Epoch 159/300\n",
      "----------\n",
      "train Loss: 0.44100338 Acc: 0.95980092\n",
      "val Loss: 0.39956395 Acc: 0.98006135\n",
      "\n",
      "Epoch 160/300\n",
      "----------\n",
      "train Loss: 0.43379896 Acc: 0.96209801\n",
      "val Loss: 0.40081399 Acc: 0.98006135\n",
      "\n",
      "Epoch 161/300\n",
      "----------\n",
      "train Loss: 0.43548713 Acc: 0.96516080\n",
      "val Loss: 0.40085917 Acc: 0.97852761\n",
      "\n",
      "Epoch 162/300\n",
      "----------\n",
      "train Loss: 0.43507616 Acc: 0.96286371\n",
      "val Loss: 0.40098259 Acc: 0.97699387\n",
      "\n",
      "Epoch 163/300\n",
      "----------\n",
      "train Loss: 0.43584593 Acc: 0.96248086\n",
      "val Loss: 0.39899137 Acc: 0.97699387\n",
      "\n",
      "Epoch 164/300\n",
      "----------\n",
      "train Loss: 0.43854562 Acc: 0.95826953\n",
      "val Loss: 0.39946410 Acc: 0.97852761\n",
      "\n",
      "Epoch 165/300\n",
      "----------\n",
      "train Loss: 0.43492547 Acc: 0.96362940\n",
      "val Loss: 0.40071108 Acc: 0.97699387\n",
      "\n",
      "Epoch 166/300\n",
      "----------\n",
      "train Loss: 0.44646209 Acc: 0.95903522\n",
      "val Loss: 0.39963914 Acc: 0.97699387\n",
      "\n",
      "Epoch 167/300\n",
      "----------\n",
      "train Loss: 0.43186331 Acc: 0.96209801\n",
      "val Loss: 0.40028394 Acc: 0.97699387\n",
      "\n",
      "Epoch 168/300\n",
      "----------\n",
      "train Loss: 0.43563337 Acc: 0.96439510\n",
      "val Loss: 0.39931650 Acc: 0.97852761\n",
      "\n",
      "Epoch 169/300\n",
      "----------\n",
      "train Loss: 0.42679968 Acc: 0.96975498\n",
      "val Loss: 0.39980231 Acc: 0.97852761\n",
      "\n",
      "Epoch 170/300\n",
      "----------\n",
      "train Loss: 0.44352578 Acc: 0.96248086\n",
      "val Loss: 0.40079936 Acc: 0.97699387\n",
      "\n",
      "Epoch 171/300\n",
      "----------\n",
      "train Loss: 0.44386113 Acc: 0.95712098\n",
      "val Loss: 0.39936254 Acc: 0.97852761\n",
      "\n",
      "Epoch 172/300\n",
      "----------\n",
      "train Loss: 0.43230423 Acc: 0.96554364\n",
      "val Loss: 0.39912214 Acc: 0.98006135\n",
      "\n",
      "Epoch 173/300\n",
      "----------\n",
      "train Loss: 0.43738735 Acc: 0.96133231\n",
      "val Loss: 0.39944953 Acc: 0.97699387\n",
      "\n",
      "Epoch 174/300\n",
      "----------\n",
      "train Loss: 0.43416110 Acc: 0.96248086\n",
      "val Loss: 0.39921486 Acc: 0.97852761\n",
      "\n",
      "Epoch 175/300\n",
      "----------\n",
      "train Loss: 0.44078360 Acc: 0.95903522\n",
      "val Loss: 0.40050888 Acc: 0.97546012\n",
      "\n",
      "Epoch 176/300\n",
      "----------\n",
      "train Loss: 0.42544920 Acc: 0.97128637\n",
      "val Loss: 0.40107870 Acc: 0.97546012\n",
      "\n",
      "Epoch 177/300\n",
      "----------\n",
      "train Loss: 0.43624875 Acc: 0.96171516\n",
      "val Loss: 0.39997223 Acc: 0.97852761\n",
      "\n",
      "Epoch 178/300\n",
      "----------\n",
      "train Loss: 0.44102811 Acc: 0.95712098\n",
      "val Loss: 0.39981013 Acc: 0.98006135\n",
      "\n",
      "Epoch 179/300\n",
      "----------\n",
      "train Loss: 0.43308968 Acc: 0.96018377\n",
      "val Loss: 0.40061160 Acc: 0.97852761\n",
      "\n",
      "Epoch 180/300\n",
      "----------\n",
      "train Loss: 0.43489482 Acc: 0.95980092\n",
      "val Loss: 0.39945019 Acc: 0.97852761\n",
      "\n",
      "Epoch 181/300\n",
      "----------\n",
      "train Loss: 0.44063437 Acc: 0.96209801\n",
      "val Loss: 0.39966685 Acc: 0.97699387\n",
      "\n",
      "Epoch 182/300\n",
      "----------\n",
      "train Loss: 0.43772345 Acc: 0.96248086\n",
      "val Loss: 0.39985098 Acc: 0.98006135\n",
      "\n",
      "Epoch 183/300\n",
      "----------\n",
      "train Loss: 0.43299381 Acc: 0.96630934\n",
      "val Loss: 0.40002797 Acc: 0.97699387\n",
      "\n",
      "Epoch 184/300\n",
      "----------\n",
      "train Loss: 0.42641805 Acc: 0.96784074\n",
      "val Loss: 0.40020295 Acc: 0.98159509\n",
      "New best model found!\n",
      "New record ACC: 0.9815950920245399, previous record acc: 0.9800613496932515\n",
      "New record acc is SAVED: 0.9815950920245399\n",
      "\n",
      "Epoch 185/300\n",
      "----------\n",
      "train Loss: 0.43509057 Acc: 0.96516080\n",
      "val Loss: 0.40004012 Acc: 0.98006135\n",
      "\n",
      "Epoch 186/300\n",
      "----------\n",
      "train Loss: 0.42981561 Acc: 0.97013783\n",
      "val Loss: 0.40007916 Acc: 0.97852761\n",
      "\n",
      "Epoch 187/300\n",
      "----------\n",
      "train Loss: 0.42974386 Acc: 0.97013783\n",
      "val Loss: 0.39991052 Acc: 0.98159509\n",
      "\n",
      "Epoch 188/300\n",
      "----------\n",
      "train Loss: 0.43305860 Acc: 0.96439510\n",
      "val Loss: 0.40018224 Acc: 0.98006135\n",
      "\n",
      "Epoch 189/300\n",
      "----------\n",
      "train Loss: 0.43286863 Acc: 0.96171516\n",
      "val Loss: 0.40056949 Acc: 0.97699387\n",
      "\n",
      "Epoch 190/300\n",
      "----------\n",
      "train Loss: 0.43163891 Acc: 0.96554364\n",
      "val Loss: 0.39992730 Acc: 0.97699387\n",
      "\n",
      "Epoch 191/300\n",
      "----------\n",
      "train Loss: 0.43289110 Acc: 0.96324655\n",
      "val Loss: 0.39946658 Acc: 0.97852761\n",
      "\n",
      "Epoch 192/300\n",
      "----------\n",
      "train Loss: 0.43076587 Acc: 0.96592649\n",
      "val Loss: 0.40034516 Acc: 0.97852761\n",
      "\n",
      "Epoch 193/300\n",
      "----------\n",
      "train Loss: 0.43395277 Acc: 0.96439510\n",
      "val Loss: 0.39953545 Acc: 0.97699387\n",
      "\n",
      "Epoch 194/300\n",
      "----------\n",
      "train Loss: 0.43626826 Acc: 0.96248086\n",
      "val Loss: 0.40146446 Acc: 0.98006135\n",
      "\n",
      "Epoch 195/300\n",
      "----------\n",
      "train Loss: 0.43492823 Acc: 0.96171516\n",
      "val Loss: 0.40006175 Acc: 0.98006135\n",
      "\n",
      "Epoch 196/300\n",
      "----------\n",
      "train Loss: 0.43633048 Acc: 0.96094946\n",
      "val Loss: 0.39984244 Acc: 0.97699387\n",
      "\n",
      "Epoch 197/300\n",
      "----------\n",
      "train Loss: 0.44311152 Acc: 0.95712098\n",
      "val Loss: 0.39972618 Acc: 0.97852761\n",
      "\n",
      "Epoch 198/300\n",
      "----------\n",
      "train Loss: 0.42891292 Acc: 0.96745789\n",
      "val Loss: 0.40005493 Acc: 0.97699387\n",
      "\n",
      "Epoch 199/300\n",
      "----------\n",
      "train Loss: 0.43831705 Acc: 0.96056662\n",
      "val Loss: 0.39940205 Acc: 0.97852761\n",
      "\n",
      "Epoch 200/300\n",
      "----------\n",
      "train Loss: 0.43167970 Acc: 0.96133231\n",
      "val Loss: 0.39964488 Acc: 0.97699387\n",
      "\n",
      "Epoch 201/300\n",
      "----------\n",
      "train Loss: 0.43724020 Acc: 0.96171516\n",
      "val Loss: 0.39867966 Acc: 0.97699387\n",
      "\n",
      "Epoch 202/300\n",
      "----------\n",
      "train Loss: 0.42905780 Acc: 0.96707504\n",
      "val Loss: 0.39991570 Acc: 0.97546012\n",
      "\n",
      "Epoch 203/300\n",
      "----------\n",
      "train Loss: 0.43865378 Acc: 0.96094946\n",
      "val Loss: 0.40034851 Acc: 0.97546012\n",
      "\n",
      "Epoch 204/300\n",
      "----------\n",
      "train Loss: 0.43979975 Acc: 0.95788668\n",
      "val Loss: 0.39970180 Acc: 0.97699387\n",
      "\n",
      "Epoch 205/300\n",
      "----------\n",
      "train Loss: 0.43140790 Acc: 0.96784074\n",
      "val Loss: 0.39935916 Acc: 0.97546012\n",
      "\n",
      "Epoch 206/300\n",
      "----------\n",
      "train Loss: 0.43594932 Acc: 0.96286371\n",
      "val Loss: 0.40032671 Acc: 0.97546012\n",
      "\n",
      "Epoch 207/300\n",
      "----------\n",
      "train Loss: 0.44389729 Acc: 0.95826953\n",
      "val Loss: 0.40022938 Acc: 0.97546012\n",
      "\n",
      "Epoch 208/300\n",
      "----------\n",
      "train Loss: 0.42567944 Acc: 0.96898928\n",
      "val Loss: 0.39982497 Acc: 0.97546012\n",
      "\n",
      "Epoch 209/300\n",
      "----------\n",
      "train Loss: 0.43116367 Acc: 0.96516080\n",
      "val Loss: 0.39957198 Acc: 0.97699387\n",
      "\n",
      "Epoch 210/300\n",
      "----------\n",
      "train Loss: 0.43333911 Acc: 0.96516080\n",
      "val Loss: 0.39976713 Acc: 0.97546012\n",
      "\n",
      "Epoch 211/300\n",
      "----------\n",
      "train Loss: 0.43273256 Acc: 0.96286371\n",
      "val Loss: 0.39991629 Acc: 0.97699387\n",
      "\n",
      "Epoch 212/300\n",
      "----------\n",
      "train Loss: 0.42651673 Acc: 0.96745789\n",
      "val Loss: 0.39997721 Acc: 0.97699387\n",
      "\n",
      "Epoch 213/300\n",
      "----------\n",
      "train Loss: 0.43082667 Acc: 0.96592649\n",
      "val Loss: 0.39980128 Acc: 0.97699387\n",
      "\n",
      "Epoch 214/300\n",
      "----------\n",
      "train Loss: 0.43469405 Acc: 0.96362940\n",
      "val Loss: 0.39973368 Acc: 0.97699387\n",
      "\n",
      "Epoch 215/300\n",
      "----------\n",
      "train Loss: 0.43321269 Acc: 0.96209801\n",
      "val Loss: 0.40008197 Acc: 0.97546012\n",
      "\n",
      "Epoch 216/300\n",
      "----------\n",
      "train Loss: 0.43697342 Acc: 0.95826953\n",
      "val Loss: 0.39972421 Acc: 0.97546012\n",
      "\n",
      "Epoch 217/300\n",
      "----------\n",
      "train Loss: 0.43421554 Acc: 0.96439510\n",
      "val Loss: 0.39982878 Acc: 0.97546012\n",
      "\n",
      "Epoch 218/300\n",
      "----------\n",
      "train Loss: 0.42484324 Acc: 0.96784074\n",
      "val Loss: 0.39962268 Acc: 0.97699387\n",
      "\n",
      "Epoch 219/300\n",
      "----------\n",
      "train Loss: 0.43508907 Acc: 0.96362940\n",
      "val Loss: 0.40027967 Acc: 0.97546012\n",
      "\n",
      "Epoch 220/300\n",
      "----------\n",
      "train Loss: 0.42804152 Acc: 0.96898928\n",
      "val Loss: 0.39982715 Acc: 0.97546012\n",
      "\n",
      "Epoch 221/300\n",
      "----------\n",
      "train Loss: 0.43394135 Acc: 0.96745789\n",
      "val Loss: 0.39950020 Acc: 0.97546012\n",
      "\n",
      "Epoch 222/300\n",
      "----------\n",
      "train Loss: 0.43177159 Acc: 0.96516080\n",
      "val Loss: 0.39980799 Acc: 0.97546012\n",
      "\n",
      "Epoch 223/300\n",
      "----------\n",
      "train Loss: 0.43488656 Acc: 0.96324655\n",
      "val Loss: 0.39964779 Acc: 0.97699387\n",
      "\n",
      "Epoch 224/300\n",
      "----------\n",
      "train Loss: 0.42974337 Acc: 0.96745789\n",
      "val Loss: 0.39984527 Acc: 0.97546012\n",
      "\n",
      "Epoch 225/300\n",
      "----------\n",
      "train Loss: 0.44191420 Acc: 0.95941807\n",
      "val Loss: 0.39916023 Acc: 0.97699387\n",
      "\n",
      "Epoch 226/300\n",
      "----------\n",
      "train Loss: 0.43311032 Acc: 0.96516080\n",
      "val Loss: 0.39996590 Acc: 0.97699387\n",
      "\n",
      "Epoch 227/300\n",
      "----------\n",
      "train Loss: 0.43452351 Acc: 0.96516080\n",
      "val Loss: 0.40028447 Acc: 0.97699387\n",
      "\n",
      "Epoch 228/300\n",
      "----------\n",
      "train Loss: 0.43319926 Acc: 0.96171516\n",
      "val Loss: 0.39986769 Acc: 0.97546012\n",
      "\n",
      "Epoch 229/300\n",
      "----------\n",
      "train Loss: 0.43638778 Acc: 0.96018377\n",
      "val Loss: 0.39914827 Acc: 0.97699387\n",
      "\n",
      "Epoch 230/300\n",
      "----------\n",
      "train Loss: 0.42840395 Acc: 0.96516080\n",
      "val Loss: 0.39915474 Acc: 0.97699387\n",
      "\n",
      "Epoch 231/300\n",
      "----------\n",
      "train Loss: 0.43470885 Acc: 0.96439510\n",
      "val Loss: 0.39985467 Acc: 0.97546012\n",
      "\n",
      "Epoch 232/300\n",
      "----------\n",
      "train Loss: 0.44000315 Acc: 0.96133231\n",
      "val Loss: 0.39956792 Acc: 0.97546012\n",
      "\n",
      "Epoch 233/300\n",
      "----------\n",
      "train Loss: 0.42763771 Acc: 0.96937213\n",
      "val Loss: 0.39957563 Acc: 0.97546012\n",
      "\n",
      "Epoch 234/300\n",
      "----------\n",
      "train Loss: 0.43175399 Acc: 0.96056662\n",
      "val Loss: 0.39908361 Acc: 0.97546012\n",
      "\n",
      "Epoch 235/300\n",
      "----------\n",
      "train Loss: 0.43212621 Acc: 0.96286371\n",
      "val Loss: 0.39965757 Acc: 0.97699387\n",
      "\n",
      "Epoch 236/300\n",
      "----------\n",
      "train Loss: 0.43904237 Acc: 0.95865237\n",
      "val Loss: 0.39993752 Acc: 0.97546012\n",
      "\n",
      "Epoch 237/300\n",
      "----------\n",
      "train Loss: 0.43286164 Acc: 0.96209801\n",
      "val Loss: 0.40029623 Acc: 0.97699387\n",
      "\n",
      "Epoch 238/300\n",
      "----------\n",
      "train Loss: 0.43208522 Acc: 0.96401225\n",
      "val Loss: 0.39967324 Acc: 0.97852761\n",
      "\n",
      "Epoch 239/300\n",
      "----------\n",
      "train Loss: 0.43018754 Acc: 0.96784074\n",
      "val Loss: 0.40015200 Acc: 0.97546012\n",
      "\n",
      "Epoch 240/300\n",
      "----------\n",
      "train Loss: 0.43282019 Acc: 0.96707504\n",
      "val Loss: 0.39965641 Acc: 0.97699387\n",
      "\n",
      "Epoch 241/300\n",
      "----------\n",
      "train Loss: 0.43534261 Acc: 0.95903522\n",
      "val Loss: 0.40004531 Acc: 0.97699387\n",
      "\n",
      "Epoch 242/300\n",
      "----------\n",
      "train Loss: 0.43724876 Acc: 0.96171516\n",
      "val Loss: 0.39942429 Acc: 0.97852761\n",
      "\n",
      "Epoch 243/300\n",
      "----------\n",
      "train Loss: 0.42584422 Acc: 0.96975498\n",
      "val Loss: 0.39873312 Acc: 0.97852761\n",
      "\n",
      "Epoch 244/300\n",
      "----------\n",
      "train Loss: 0.43113244 Acc: 0.96745789\n",
      "val Loss: 0.39958850 Acc: 0.97546012\n",
      "\n",
      "Epoch 245/300\n",
      "----------\n",
      "train Loss: 0.43470243 Acc: 0.96362940\n",
      "val Loss: 0.39957411 Acc: 0.97699387\n",
      "\n",
      "Epoch 246/300\n",
      "----------\n",
      "train Loss: 0.42976940 Acc: 0.96554364\n",
      "val Loss: 0.39980417 Acc: 0.97546012\n",
      "\n",
      "Epoch 247/300\n",
      "----------\n",
      "train Loss: 0.43583389 Acc: 0.96554364\n",
      "val Loss: 0.40078719 Acc: 0.97852761\n",
      "\n",
      "Epoch 248/300\n",
      "----------\n",
      "train Loss: 0.43111884 Acc: 0.96362940\n",
      "val Loss: 0.40000955 Acc: 0.98006135\n",
      "\n",
      "Epoch 249/300\n",
      "----------\n",
      "train Loss: 0.43859625 Acc: 0.95980092\n",
      "val Loss: 0.39984483 Acc: 0.97699387\n",
      "\n",
      "Epoch 250/300\n",
      "----------\n",
      "train Loss: 0.44355863 Acc: 0.95941807\n",
      "val Loss: 0.40029131 Acc: 0.97699387\n",
      "\n",
      "Epoch 251/300\n",
      "----------\n",
      "train Loss: 0.42974196 Acc: 0.96477795\n",
      "val Loss: 0.39992146 Acc: 0.97699387\n",
      "\n",
      "Epoch 252/300\n",
      "----------\n",
      "train Loss: 0.43571346 Acc: 0.96439510\n",
      "val Loss: 0.39908581 Acc: 0.97699387\n",
      "\n",
      "Epoch 253/300\n",
      "----------\n",
      "train Loss: 0.42848116 Acc: 0.96822358\n",
      "val Loss: 0.39961326 Acc: 0.97546012\n",
      "\n",
      "Epoch 254/300\n",
      "----------\n",
      "train Loss: 0.43041041 Acc: 0.96745789\n",
      "val Loss: 0.39955225 Acc: 0.97852761\n",
      "\n",
      "Epoch 255/300\n",
      "----------\n",
      "train Loss: 0.43029915 Acc: 0.96669219\n",
      "val Loss: 0.39972222 Acc: 0.97852761\n",
      "\n",
      "Epoch 256/300\n",
      "----------\n",
      "train Loss: 0.43283632 Acc: 0.96669219\n",
      "val Loss: 0.39983065 Acc: 0.97546012\n",
      "\n",
      "Epoch 257/300\n",
      "----------\n",
      "train Loss: 0.44037068 Acc: 0.96248086\n",
      "val Loss: 0.39932396 Acc: 0.97699387\n",
      "\n",
      "Epoch 258/300\n",
      "----------\n",
      "train Loss: 0.42649326 Acc: 0.96898928\n",
      "val Loss: 0.39924240 Acc: 0.97699387\n",
      "\n",
      "Epoch 259/300\n",
      "----------\n",
      "train Loss: 0.43727175 Acc: 0.96133231\n",
      "val Loss: 0.39969660 Acc: 0.97699387\n",
      "\n",
      "Epoch 260/300\n",
      "----------\n",
      "train Loss: 0.43199353 Acc: 0.96362940\n",
      "val Loss: 0.39869857 Acc: 0.97699387\n",
      "\n",
      "Epoch 261/300\n",
      "----------\n",
      "train Loss: 0.43465085 Acc: 0.95980092\n",
      "val Loss: 0.39896757 Acc: 0.97852761\n",
      "\n",
      "Epoch 262/300\n",
      "----------\n",
      "train Loss: 0.43099189 Acc: 0.96362940\n",
      "val Loss: 0.39927912 Acc: 0.97699387\n",
      "\n",
      "Epoch 263/300\n",
      "----------\n",
      "train Loss: 0.43202626 Acc: 0.96286371\n",
      "val Loss: 0.39920997 Acc: 0.97699387\n",
      "\n",
      "Epoch 264/300\n",
      "----------\n",
      "train Loss: 0.43136638 Acc: 0.96362940\n",
      "val Loss: 0.39929959 Acc: 0.97546012\n",
      "\n",
      "Epoch 265/300\n",
      "----------\n",
      "train Loss: 0.42849463 Acc: 0.96745789\n",
      "val Loss: 0.39969848 Acc: 0.97546012\n",
      "\n",
      "Epoch 266/300\n",
      "----------\n",
      "train Loss: 0.42943738 Acc: 0.96630934\n",
      "val Loss: 0.39919808 Acc: 0.97699387\n",
      "\n",
      "Epoch 267/300\n",
      "----------\n",
      "train Loss: 0.43113832 Acc: 0.96248086\n",
      "val Loss: 0.39947002 Acc: 0.97546012\n",
      "\n",
      "Epoch 268/300\n",
      "----------\n",
      "train Loss: 0.43071196 Acc: 0.96477795\n",
      "val Loss: 0.39970335 Acc: 0.97546012\n",
      "\n",
      "Epoch 269/300\n",
      "----------\n",
      "train Loss: 0.42851590 Acc: 0.96745789\n",
      "val Loss: 0.39952463 Acc: 0.97392638\n",
      "\n",
      "Epoch 270/300\n",
      "----------\n",
      "train Loss: 0.43233511 Acc: 0.96745789\n",
      "val Loss: 0.39973151 Acc: 0.97392638\n",
      "\n",
      "Epoch 271/300\n",
      "----------\n",
      "train Loss: 0.43218011 Acc: 0.96630934\n",
      "val Loss: 0.39946822 Acc: 0.97699387\n",
      "\n",
      "Epoch 272/300\n",
      "----------\n",
      "train Loss: 0.42747535 Acc: 0.96784074\n",
      "val Loss: 0.39895308 Acc: 0.97699387\n",
      "\n",
      "Epoch 273/300\n",
      "----------\n",
      "train Loss: 0.43425583 Acc: 0.95788668\n",
      "val Loss: 0.39879674 Acc: 0.97699387\n",
      "\n",
      "Epoch 274/300\n",
      "----------\n",
      "train Loss: 0.43634509 Acc: 0.96286371\n",
      "val Loss: 0.39980169 Acc: 0.97546012\n",
      "\n",
      "Epoch 275/300\n",
      "----------\n",
      "train Loss: 0.43481017 Acc: 0.96286371\n",
      "val Loss: 0.40020716 Acc: 0.97852761\n",
      "\n",
      "Epoch 276/300\n",
      "----------\n",
      "train Loss: 0.43142240 Acc: 0.96401225\n",
      "val Loss: 0.39944427 Acc: 0.97699387\n",
      "\n",
      "Epoch 277/300\n",
      "----------\n",
      "train Loss: 0.43881111 Acc: 0.95865237\n",
      "val Loss: 0.39935247 Acc: 0.97546012\n",
      "\n",
      "Epoch 278/300\n",
      "----------\n",
      "train Loss: 0.42537609 Acc: 0.97013783\n",
      "val Loss: 0.39914536 Acc: 0.97852761\n",
      "\n",
      "Epoch 279/300\n",
      "----------\n",
      "train Loss: 0.43850353 Acc: 0.95865237\n",
      "val Loss: 0.39856913 Acc: 0.98006135\n",
      "\n",
      "Epoch 280/300\n",
      "----------\n",
      "train Loss: 0.43101670 Acc: 0.96592649\n",
      "val Loss: 0.39985591 Acc: 0.97699387\n",
      "\n",
      "Epoch 281/300\n",
      "----------\n",
      "train Loss: 0.43834036 Acc: 0.96286371\n",
      "val Loss: 0.39946114 Acc: 0.97546012\n",
      "\n",
      "Epoch 282/300\n",
      "----------\n",
      "train Loss: 0.43859783 Acc: 0.95980092\n",
      "val Loss: 0.40047578 Acc: 0.97546012\n",
      "\n",
      "Epoch 283/300\n",
      "----------\n",
      "train Loss: 0.43539213 Acc: 0.96248086\n",
      "val Loss: 0.39933739 Acc: 0.97699387\n",
      "\n",
      "Epoch 284/300\n",
      "----------\n",
      "train Loss: 0.43235979 Acc: 0.96516080\n",
      "val Loss: 0.39993439 Acc: 0.97699387\n",
      "\n",
      "Epoch 285/300\n",
      "----------\n",
      "train Loss: 0.43686301 Acc: 0.96056662\n",
      "val Loss: 0.39979688 Acc: 0.97546012\n",
      "\n",
      "Epoch 286/300\n",
      "----------\n",
      "train Loss: 0.42443077 Acc: 0.97243492\n",
      "val Loss: 0.39906581 Acc: 0.97699387\n",
      "\n",
      "Epoch 287/300\n",
      "----------\n",
      "train Loss: 0.42378737 Acc: 0.97166922\n",
      "val Loss: 0.39951090 Acc: 0.97699387\n",
      "\n",
      "Epoch 288/300\n",
      "----------\n",
      "train Loss: 0.42915506 Acc: 0.96554364\n",
      "val Loss: 0.39973246 Acc: 0.97699387\n",
      "\n",
      "Epoch 289/300\n",
      "----------\n",
      "train Loss: 0.43299261 Acc: 0.96630934\n",
      "val Loss: 0.40025349 Acc: 0.97546012\n",
      "\n",
      "Epoch 290/300\n",
      "----------\n",
      "train Loss: 0.43748348 Acc: 0.96248086\n",
      "val Loss: 0.39909588 Acc: 0.97546012\n",
      "\n",
      "Epoch 291/300\n",
      "----------\n",
      "train Loss: 0.43113960 Acc: 0.96745789\n",
      "val Loss: 0.40005906 Acc: 0.97699387\n",
      "\n",
      "Epoch 292/300\n",
      "----------\n",
      "train Loss: 0.42348287 Acc: 0.97052067\n",
      "val Loss: 0.39938393 Acc: 0.97699387\n",
      "\n",
      "Epoch 293/300\n",
      "----------\n",
      "train Loss: 0.42365385 Acc: 0.97128637\n",
      "val Loss: 0.39978142 Acc: 0.97699387\n",
      "\n",
      "Epoch 294/300\n",
      "----------\n",
      "train Loss: 0.43562020 Acc: 0.96630934\n",
      "val Loss: 0.40019979 Acc: 0.97699387\n",
      "\n",
      "Epoch 295/300\n",
      "----------\n",
      "train Loss: 0.43275850 Acc: 0.96094946\n",
      "val Loss: 0.40030416 Acc: 0.97699387\n",
      "\n",
      "Epoch 296/300\n",
      "----------\n",
      "train Loss: 0.42373344 Acc: 0.96707504\n",
      "val Loss: 0.39909874 Acc: 0.97699387\n",
      "\n",
      "Epoch 297/300\n",
      "----------\n",
      "train Loss: 0.43590570 Acc: 0.96286371\n",
      "val Loss: 0.39955191 Acc: 0.97546012\n",
      "\n",
      "Epoch 298/300\n",
      "----------\n",
      "train Loss: 0.42072800 Acc: 0.97243492\n",
      "val Loss: 0.40003927 Acc: 0.97699387\n",
      "\n",
      "Epoch 299/300\n",
      "----------\n",
      "train Loss: 0.42990438 Acc: 0.96324655\n",
      "val Loss: 0.39957971 Acc: 0.97546012\n",
      "\n",
      "Epoch 300/300\n",
      "----------\n",
      "train Loss: 0.42923655 Acc: 0.96554364\n",
      "val Loss: 0.40033071 Acc: 0.97546012\n",
      "\n",
      "Training complete in 61m 17s\n",
      "Best val Acc: 0.98159509 Best val loss: 0.40020295\n"
     ]
    }
   ],
   "source": [
    "CHECK_POINT_PATH = '/home/linh/Downloads/Brain/weights/EfficientNet_B0_V2.pth'\n",
    "try:\n",
    "    checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "    print(\"checkpoint loaded\")\n",
    "except:\n",
    "    checkpoint = None\n",
    "    print(\"checkpoint not found\")\n",
    "if checkpoint == None:\n",
    "    CHECK_POINT_PATH = CHECK_POINT_PATH\n",
    "model, best_val_loss, best_val_acc = train_model(model,\n",
    "                                                 criterion,\n",
    "                                                 optimizer,\n",
    "                                                 scheduler,\n",
    "                                                 num_epochs = 300,\n",
    "                                                 checkpoint = None #torch.load(CHECK_POINT_PATH)\n",
    "                                                 ) \n",
    "                                                \n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, CHECK_POINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19_EfficientNet_B0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
