{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40178,
     "status": "ok",
     "timestamp": 1588213047201,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "rPwL9bdoBNzQ",
    "outputId": "553f83f0-cbf1-48d5-a184-4f4c8ff055ac"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PIL\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "#from pytorch_metric_learning import loss\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from timm.models.layers.activations import *\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from randaugment import RandAugment, ImageNetPolicy, Cutout\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179460,
     "status": "ok",
     "timestamp": 1588213186502,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "584ea32f-dbe1-4465-8e60-e0f4e5c96a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Glioma', 'Meningioma', 'No_Tumor', 'Pituitary']\n",
      "{'train': 2870, 'val': 394}\n",
      "cuda:0\n",
      "{0: 'Glioma', 1: 'Meningioma', 2: 'No_Tumor', 3: 'Pituitary'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([140, 3, 224, 224])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/home/linh/Downloads/Brain/'\n",
    "\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        ImageNetPolicy(),\n",
    "        Cutout(size=16),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "batch_size = 140\n",
    "data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4, pin_memory = True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)\n",
    "print(dataset_sizes)\n",
    "print(device)\n",
    "\n",
    "### we get the class_to_index in the data_Set but what we really need is the cat_to_names  so we will create\n",
    "_ = image_datasets['train'].class_to_idx\n",
    "cat_to_name = {_[i]: i for i in list(_.keys())}\n",
    "print(cat_to_name)\n",
    "    \n",
    "# Run this to test the data loader\n",
    "images, labels = next(iter(data_loader['val']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226470,
     "status": "ok",
     "timestamp": 1588213233519,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "N350JAHpu8c3",
    "outputId": "96a2d095-f78f-4ca5-eb0c-c5390e367831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def showimage(data_loader, number_images, cat_to_name):\\n    dataiter = iter(data_loader)\\n    images, labels = dataiter.next()\\n    images = images.numpy() # convert images to numpy for display\\n    # plot the images in the batch, along with the corresponding labels\\n    fig = plt.figure(figsize=(number_images, 4))\\n    for idx in np.arange(number_images):\\n        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\\n        img = np.transpose(images[idx])\\n        plt.imshow(img)\\n        ax.set_title(cat_to_name[labels.tolist()[idx]])\\n        \\n#### to show some  images\\nshowimage(data_loader['test'], 20, cat_to_name)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def showimage(data_loader, number_images, cat_to_name):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.numpy() # convert images to numpy for display\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(number_images, 4))\n",
    "    for idx in np.arange(number_images):\n",
    "        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\n",
    "        img = np.transpose(images[idx])\n",
    "        plt.imshow(img)\n",
    "        ax.set_title(cat_to_name[labels.tolist()[idx]])\n",
    "        \n",
    "#### to show some  images\n",
    "showimage(data_loader['test'], 20, cat_to_name)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226461,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "L9jdFtBjSAE6",
    "outputId": "f0f393c5-4369-422c-9aef-fc290ccc941d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierHead(\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = models.resnet50(pretrained=True)\n",
    "#model = timm.create_model('resnet50', pretrained=True)\n",
    "model = timm.create_model('tresnet_m', num_classes=4,pretrained=True)\n",
    "#model.fc #show fully connected layer for ResNet family\n",
    "model.head #show the classifier layer (fully connected layer) for EfficientNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226454,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "6beb0600-5fdf-4ae6-a216-40c32a13bb9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29348228\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# define `classifier` for ResNet\n",
    "# Otherwise, define `fc` for EfficientNet family \n",
    "#because the definition of the full connection/classifier of 2 CNN families is differnt\n",
    "'''classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(2048, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, 4)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "# connect base model (EfficientNet_B0) with modified classifier layer\n",
    "model.fc = classifier'''\n",
    "criterion = LabelSmoothingCrossEntropy()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Nadam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.01,momentum=0.9,\n",
    "                      nesterov=True,\n",
    "                      weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=80, gamma=0.1)\n",
    "#show our model architechture and send to GPU\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPNx-TodPpVA"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=200, checkpoint = None):\n",
    "    since = time.time()\n",
    "\n",
    "    if checkpoint is None:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = math.inf\n",
    "        best_acc = 0.\n",
    "    else:\n",
    "        print(f'Val loss: {checkpoint[\"best_val_loss\"]}, Val accuracy: {checkpoint[\"best_val_accuracy\"]}')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "   \n",
    "    # Tensorboard summary\n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs)) #(epoch, num_epochs -1)\n",
    "        print('-' * 20)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(data_loader[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if i % 1000 == 999:\n",
    "                    print('[%d, %d] loss: %.8f' % \n",
    "                          (epoch + 1, i, running_loss / (i * inputs.size(0))))\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':                \n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.8f} Acc: {:.8f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # Record training loss and accuracy for each phase\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Train/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            else:\n",
    "                writer.add_scalar('Valid/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Valid/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            # deep copy the model\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                print(f'New best model found!')\n",
    "                print(f'New record ACC: {epoch_acc}, previous record acc: {best_acc}')\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'best_val_loss': best_loss,\n",
    "                            'best_val_accuracy': best_acc,\n",
    "                            'scheduler_state_dict' : scheduler.state_dict(),\n",
    "                            }, \n",
    "                            CHECK_POINT_PATH\n",
    "                            )\n",
    "                print(f'New record acc is SAVED: {epoch_acc}')\n",
    "\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.8f} Best val loss: {:.8f}'.format(best_acc, best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vcXkJFOlP4NJ",
    "outputId": "e47fadb8-c292-4051-8a56-bbdc5868abe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint not found\n",
      "Epoch 1/300\n",
      "--------------------\n",
      "train Loss: 1.07955691 Acc: 0.57595819\n",
      "val Loss: 1.28092318 Acc: 0.53045685\n",
      "New best model found!\n",
      "New record ACC: 0.5304568527918782, previous record acc: 0.0\n",
      "New record acc is SAVED: 0.5304568527918782\n",
      "\n",
      "Epoch 2/300\n",
      "--------------------\n",
      "train Loss: 0.77862053 Acc: 0.78222997\n",
      "val Loss: 1.07722064 Acc: 0.65736041\n",
      "New best model found!\n",
      "New record ACC: 0.6573604060913705, previous record acc: 0.5304568527918782\n",
      "New record acc is SAVED: 0.6573604060913705\n",
      "\n",
      "Epoch 3/300\n",
      "--------------------\n",
      "train Loss: 0.69188676 Acc: 0.82055749\n",
      "val Loss: 0.99619725 Acc: 0.70304569\n",
      "New best model found!\n",
      "New record ACC: 0.7030456852791878, previous record acc: 0.6573604060913705\n",
      "New record acc is SAVED: 0.7030456852791878\n",
      "\n",
      "Epoch 4/300\n",
      "--------------------\n",
      "train Loss: 0.65551965 Acc: 0.84355401\n",
      "val Loss: 0.93008084 Acc: 0.76649746\n",
      "New best model found!\n",
      "New record ACC: 0.766497461928934, previous record acc: 0.7030456852791878\n",
      "New record acc is SAVED: 0.766497461928934\n",
      "\n",
      "Epoch 5/300\n",
      "--------------------\n",
      "train Loss: 0.61635884 Acc: 0.86794425\n",
      "val Loss: 0.93981691 Acc: 0.75634518\n",
      "\n",
      "Epoch 6/300\n",
      "--------------------\n",
      "train Loss: 0.60247049 Acc: 0.86550523\n",
      "val Loss: 0.89187448 Acc: 0.78172589\n",
      "New best model found!\n",
      "New record ACC: 0.781725888324873, previous record acc: 0.766497461928934\n",
      "New record acc is SAVED: 0.781725888324873\n",
      "\n",
      "Epoch 7/300\n",
      "--------------------\n",
      "train Loss: 0.56582597 Acc: 0.89024390\n",
      "val Loss: 0.92371932 Acc: 0.76903553\n",
      "\n",
      "Epoch 8/300\n",
      "--------------------\n",
      "train Loss: 0.55891211 Acc: 0.89965157\n",
      "val Loss: 0.81821413 Acc: 0.82233503\n",
      "New best model found!\n",
      "New record ACC: 0.8223350253807106, previous record acc: 0.781725888324873\n",
      "New record acc is SAVED: 0.8223350253807106\n",
      "\n",
      "Epoch 9/300\n",
      "--------------------\n",
      "train Loss: 0.54806927 Acc: 0.90174216\n",
      "val Loss: 0.93988984 Acc: 0.75126904\n",
      "\n",
      "Epoch 10/300\n",
      "--------------------\n",
      "train Loss: 0.52870543 Acc: 0.91533101\n",
      "val Loss: 0.83479353 Acc: 0.79695431\n",
      "\n",
      "Epoch 11/300\n",
      "--------------------\n",
      "train Loss: 0.51947024 Acc: 0.91777003\n",
      "val Loss: 0.84170746 Acc: 0.79695431\n",
      "\n",
      "Epoch 12/300\n",
      "--------------------\n",
      "train Loss: 0.50844645 Acc: 0.92229965\n",
      "val Loss: 0.83579027 Acc: 0.79695431\n",
      "\n",
      "Epoch 13/300\n",
      "--------------------\n",
      "train Loss: 0.50783221 Acc: 0.92055749\n",
      "val Loss: 0.88775407 Acc: 0.79187817\n",
      "\n",
      "Epoch 14/300\n",
      "--------------------\n",
      "train Loss: 0.50206799 Acc: 0.92299652\n",
      "val Loss: 0.78638785 Acc: 0.82741117\n",
      "New best model found!\n",
      "New record ACC: 0.8274111675126903, previous record acc: 0.8223350253807106\n",
      "New record acc is SAVED: 0.8274111675126903\n",
      "\n",
      "Epoch 15/300\n",
      "--------------------\n",
      "train Loss: 0.49438596 Acc: 0.92613240\n",
      "val Loss: 0.80583147 Acc: 0.82233503\n",
      "\n",
      "Epoch 16/300\n",
      "--------------------\n",
      "train Loss: 0.50242820 Acc: 0.92160279\n",
      "val Loss: 0.78018884 Acc: 0.82994924\n",
      "New best model found!\n",
      "New record ACC: 0.8299492385786802, previous record acc: 0.8274111675126903\n",
      "New record acc is SAVED: 0.8299492385786802\n",
      "\n",
      "Epoch 17/300\n",
      "--------------------\n",
      "train Loss: 0.49302235 Acc: 0.92682927\n",
      "val Loss: 0.76683039 Acc: 0.82233503\n",
      "\n",
      "Epoch 18/300\n",
      "--------------------\n",
      "train Loss: 0.48004893 Acc: 0.93658537\n",
      "val Loss: 0.75718068 Acc: 0.83502538\n",
      "New best model found!\n",
      "New record ACC: 0.8350253807106598, previous record acc: 0.8299492385786802\n",
      "New record acc is SAVED: 0.8350253807106598\n",
      "\n",
      "Epoch 19/300\n",
      "--------------------\n",
      "train Loss: 0.47862971 Acc: 0.93832753\n",
      "val Loss: 0.74972339 Acc: 0.83248731\n",
      "\n",
      "Epoch 20/300\n",
      "--------------------\n",
      "train Loss: 0.47506818 Acc: 0.93623693\n",
      "val Loss: 0.70355875 Acc: 0.86294416\n",
      "New best model found!\n",
      "New record ACC: 0.8629441624365481, previous record acc: 0.8350253807106598\n",
      "New record acc is SAVED: 0.8629441624365481\n",
      "\n",
      "Epoch 21/300\n",
      "--------------------\n",
      "train Loss: 0.48691467 Acc: 0.93275261\n",
      "val Loss: 0.73884114 Acc: 0.83756345\n",
      "\n",
      "Epoch 22/300\n",
      "--------------------\n",
      "train Loss: 0.46591006 Acc: 0.94494774\n",
      "val Loss: 0.69804413 Acc: 0.86040609\n",
      "\n",
      "Epoch 23/300\n",
      "--------------------\n",
      "train Loss: 0.46908571 Acc: 0.94006969\n",
      "val Loss: 0.78639412 Acc: 0.83248731\n",
      "\n",
      "Epoch 24/300\n",
      "--------------------\n",
      "train Loss: 0.46191247 Acc: 0.94668990\n",
      "val Loss: 0.81434298 Acc: 0.82233503\n",
      "\n",
      "Epoch 25/300\n",
      "--------------------\n",
      "train Loss: 0.46491889 Acc: 0.94425087\n",
      "val Loss: 0.87985800 Acc: 0.79949239\n",
      "\n",
      "Epoch 26/300\n",
      "--------------------\n",
      "train Loss: 0.46328794 Acc: 0.94216028\n",
      "val Loss: 0.77533215 Acc: 0.82487310\n",
      "\n",
      "Epoch 27/300\n",
      "--------------------\n",
      "train Loss: 0.46005933 Acc: 0.94494774\n",
      "val Loss: 0.79527310 Acc: 0.83248731\n",
      "\n",
      "Epoch 28/300\n",
      "--------------------\n",
      "train Loss: 0.45584408 Acc: 0.94529617\n",
      "val Loss: 0.77031647 Acc: 0.82741117\n",
      "\n",
      "Epoch 29/300\n",
      "--------------------\n",
      "train Loss: 0.45580589 Acc: 0.94947735\n",
      "val Loss: 0.82999220 Acc: 0.81472081\n",
      "\n",
      "Epoch 30/300\n",
      "--------------------\n",
      "train Loss: 0.46711184 Acc: 0.93972125\n",
      "val Loss: 0.77312013 Acc: 0.83248731\n",
      "\n",
      "Epoch 31/300\n",
      "--------------------\n",
      "train Loss: 0.46279705 Acc: 0.94773519\n",
      "val Loss: 0.74708271 Acc: 0.85786802\n",
      "\n",
      "Epoch 32/300\n",
      "--------------------\n",
      "train Loss: 0.45972006 Acc: 0.94390244\n",
      "val Loss: 0.75585001 Acc: 0.83502538\n",
      "\n",
      "Epoch 33/300\n",
      "--------------------\n",
      "train Loss: 0.45161296 Acc: 0.95121951\n",
      "val Loss: 0.77462223 Acc: 0.84010152\n",
      "\n",
      "Epoch 34/300\n",
      "--------------------\n",
      "train Loss: 0.45242023 Acc: 0.94634146\n",
      "val Loss: 0.74412737 Acc: 0.85786802\n",
      "\n",
      "Epoch 35/300\n",
      "--------------------\n",
      "train Loss: 0.45196337 Acc: 0.95191638\n",
      "val Loss: 0.75529295 Acc: 0.85025381\n",
      "\n",
      "Epoch 36/300\n",
      "--------------------\n",
      "train Loss: 0.44009197 Acc: 0.95540070\n",
      "val Loss: 0.83414264 Acc: 0.81725888\n",
      "\n",
      "Epoch 37/300\n",
      "--------------------\n",
      "train Loss: 0.44070122 Acc: 0.95574913\n",
      "val Loss: 0.76894827 Acc: 0.84263959\n",
      "\n",
      "Epoch 38/300\n",
      "--------------------\n",
      "train Loss: 0.42759520 Acc: 0.96445993\n",
      "val Loss: 0.76732480 Acc: 0.82994924\n",
      "\n",
      "Epoch 39/300\n",
      "--------------------\n",
      "train Loss: 0.44666263 Acc: 0.95121951\n",
      "val Loss: 0.81133180 Acc: 0.81979695\n",
      "\n",
      "Epoch 40/300\n",
      "--------------------\n",
      "train Loss: 0.43544375 Acc: 0.95749129\n",
      "val Loss: 0.77528378 Acc: 0.84010152\n",
      "\n",
      "Epoch 41/300\n",
      "--------------------\n",
      "train Loss: 0.43988246 Acc: 0.95749129\n",
      "val Loss: 0.76002305 Acc: 0.83756345\n",
      "\n",
      "Epoch 42/300\n",
      "--------------------\n",
      "train Loss: 0.44142167 Acc: 0.95714286\n",
      "val Loss: 0.78112182 Acc: 0.82487310\n",
      "\n",
      "Epoch 43/300\n",
      "--------------------\n",
      "train Loss: 0.43722423 Acc: 0.95923345\n",
      "val Loss: 0.78719612 Acc: 0.82741117\n",
      "\n",
      "Epoch 44/300\n",
      "--------------------\n",
      "train Loss: 0.43162573 Acc: 0.96062718\n",
      "val Loss: 0.81782086 Acc: 0.82487310\n",
      "\n",
      "Epoch 45/300\n",
      "--------------------\n",
      "train Loss: 0.43226431 Acc: 0.95714286\n",
      "val Loss: 0.77202790 Acc: 0.82994924\n",
      "\n",
      "Epoch 46/300\n",
      "--------------------\n",
      "train Loss: 0.43042657 Acc: 0.95749129\n",
      "val Loss: 0.82802807 Acc: 0.81218274\n",
      "\n",
      "Epoch 47/300\n",
      "--------------------\n",
      "train Loss: 0.43623541 Acc: 0.95888502\n",
      "val Loss: 0.73697588 Acc: 0.84517766\n",
      "\n",
      "Epoch 48/300\n",
      "--------------------\n",
      "train Loss: 0.42510746 Acc: 0.96376307\n",
      "val Loss: 0.75045471 Acc: 0.83756345\n",
      "\n",
      "Epoch 49/300\n",
      "--------------------\n",
      "train Loss: 0.42998085 Acc: 0.96306620\n",
      "val Loss: 0.83359613 Acc: 0.82233503\n",
      "\n",
      "Epoch 50/300\n",
      "--------------------\n",
      "train Loss: 0.43108792 Acc: 0.96027875\n",
      "val Loss: 0.83352725 Acc: 0.81472081\n",
      "\n",
      "Epoch 51/300\n",
      "--------------------\n",
      "train Loss: 0.44001133 Acc: 0.95574913\n",
      "val Loss: 0.77959656 Acc: 0.83756345\n",
      "\n",
      "Epoch 52/300\n",
      "--------------------\n",
      "train Loss: 0.43457917 Acc: 0.95574913\n",
      "val Loss: 0.80145788 Acc: 0.84517766\n",
      "\n",
      "Epoch 53/300\n",
      "--------------------\n",
      "train Loss: 0.43746230 Acc: 0.95679443\n",
      "val Loss: 0.80634653 Acc: 0.84263959\n",
      "\n",
      "Epoch 54/300\n",
      "--------------------\n",
      "train Loss: 0.43488286 Acc: 0.95644599\n",
      "val Loss: 0.74482666 Acc: 0.85279188\n",
      "\n",
      "Epoch 55/300\n",
      "--------------------\n",
      "train Loss: 0.43307004 Acc: 0.95783972\n",
      "val Loss: 0.78359570 Acc: 0.83756345\n",
      "\n",
      "Epoch 56/300\n",
      "--------------------\n",
      "train Loss: 0.42531417 Acc: 0.96027875\n",
      "val Loss: 0.79628814 Acc: 0.84263959\n",
      "\n",
      "Epoch 57/300\n",
      "--------------------\n",
      "train Loss: 0.42359076 Acc: 0.96724739\n",
      "val Loss: 0.77963397 Acc: 0.83756345\n",
      "\n",
      "Epoch 58/300\n",
      "--------------------\n",
      "train Loss: 0.42435722 Acc: 0.96167247\n",
      "val Loss: 0.80725921 Acc: 0.84010152\n",
      "\n",
      "Epoch 59/300\n",
      "--------------------\n",
      "train Loss: 0.42360077 Acc: 0.96794425\n",
      "val Loss: 0.84035984 Acc: 0.81472081\n",
      "\n",
      "Epoch 60/300\n",
      "--------------------\n",
      "train Loss: 0.43254929 Acc: 0.96097561\n",
      "val Loss: 0.82975231 Acc: 0.83248731\n",
      "\n",
      "Epoch 61/300\n",
      "--------------------\n",
      "train Loss: 0.41721838 Acc: 0.96655052\n",
      "val Loss: 0.82486998 Acc: 0.83248731\n",
      "\n",
      "Epoch 62/300\n",
      "--------------------\n",
      "train Loss: 0.42029893 Acc: 0.96550523\n",
      "val Loss: 0.74322473 Acc: 0.83502538\n",
      "\n",
      "Epoch 63/300\n",
      "--------------------\n",
      "train Loss: 0.42967167 Acc: 0.96167247\n",
      "val Loss: 0.71126670 Acc: 0.85532995\n",
      "\n",
      "Epoch 64/300\n",
      "--------------------\n",
      "train Loss: 0.41640477 Acc: 0.96585366\n",
      "val Loss: 0.82202418 Acc: 0.82994924\n",
      "\n",
      "Epoch 65/300\n",
      "--------------------\n",
      "train Loss: 0.41519830 Acc: 0.96968641\n",
      "val Loss: 0.81712575 Acc: 0.82487310\n",
      "\n",
      "Epoch 66/300\n",
      "--------------------\n",
      "train Loss: 0.43081548 Acc: 0.95853659\n",
      "val Loss: 0.75043372 Acc: 0.84517766\n",
      "\n",
      "Epoch 67/300\n",
      "--------------------\n",
      "train Loss: 0.42002539 Acc: 0.96550523\n",
      "val Loss: 0.72689663 Acc: 0.85786802\n",
      "\n",
      "Epoch 68/300\n",
      "--------------------\n",
      "train Loss: 0.44961827 Acc: 0.94808362\n",
      "val Loss: 0.82575576 Acc: 0.80203046\n",
      "\n",
      "Epoch 69/300\n",
      "--------------------\n",
      "train Loss: 0.45122380 Acc: 0.94982578\n",
      "val Loss: 0.74786557 Acc: 0.83502538\n",
      "\n",
      "Epoch 70/300\n",
      "--------------------\n",
      "train Loss: 0.43561756 Acc: 0.95923345\n",
      "val Loss: 0.71986518 Acc: 0.84517766\n",
      "\n",
      "Epoch 71/300\n",
      "--------------------\n",
      "train Loss: 0.44186756 Acc: 0.95226481\n",
      "val Loss: 0.69362317 Acc: 0.86040609\n",
      "\n",
      "Epoch 72/300\n",
      "--------------------\n",
      "train Loss: 0.42745571 Acc: 0.96202091\n",
      "val Loss: 0.75049616 Acc: 0.84010152\n",
      "\n",
      "Epoch 73/300\n",
      "--------------------\n",
      "train Loss: 0.42904225 Acc: 0.96132404\n",
      "val Loss: 0.70728105 Acc: 0.86040609\n",
      "\n",
      "Epoch 74/300\n",
      "--------------------\n",
      "train Loss: 0.43073680 Acc: 0.95679443\n",
      "val Loss: 0.66716083 Acc: 0.88578680\n",
      "New best model found!\n",
      "New record ACC: 0.8857868020304568, previous record acc: 0.8629441624365481\n",
      "New record acc is SAVED: 0.8857868020304568\n",
      "\n",
      "Epoch 75/300\n",
      "--------------------\n",
      "train Loss: 0.41961109 Acc: 0.96585366\n",
      "val Loss: 0.74408713 Acc: 0.84771574\n",
      "\n",
      "Epoch 76/300\n",
      "--------------------\n",
      "train Loss: 0.42817543 Acc: 0.96236934\n",
      "val Loss: 0.67087705 Acc: 0.87817259\n",
      "\n",
      "Epoch 77/300\n",
      "--------------------\n",
      "train Loss: 0.42548585 Acc: 0.96132404\n",
      "val Loss: 0.74113382 Acc: 0.84771574\n",
      "\n",
      "Epoch 78/300\n",
      "--------------------\n",
      "train Loss: 0.41624432 Acc: 0.97038328\n",
      "val Loss: 0.77202074 Acc: 0.84010152\n",
      "\n",
      "Epoch 79/300\n",
      "--------------------\n",
      "train Loss: 0.43011832 Acc: 0.95818815\n",
      "val Loss: 0.74556210 Acc: 0.86040609\n",
      "\n",
      "Epoch 80/300\n",
      "--------------------\n",
      "train Loss: 0.41152218 Acc: 0.97212544\n",
      "val Loss: 0.71936851 Acc: 0.86040609\n",
      "\n",
      "Epoch 81/300\n",
      "--------------------\n",
      "train Loss: 0.42109304 Acc: 0.96550523\n",
      "val Loss: 0.73785654 Acc: 0.85786802\n",
      "\n",
      "Epoch 82/300\n",
      "--------------------\n",
      "train Loss: 0.41572437 Acc: 0.96829268\n",
      "val Loss: 0.72824530 Acc: 0.85786802\n",
      "\n",
      "Epoch 83/300\n",
      "--------------------\n",
      "train Loss: 0.41104174 Acc: 0.97108014\n",
      "val Loss: 0.74280316 Acc: 0.85786802\n",
      "\n",
      "Epoch 84/300\n",
      "--------------------\n",
      "train Loss: 0.40780332 Acc: 0.97038328\n",
      "val Loss: 0.72880073 Acc: 0.86548223\n",
      "\n",
      "Epoch 85/300\n",
      "--------------------\n",
      "train Loss: 0.41485920 Acc: 0.96480836\n",
      "val Loss: 0.73432602 Acc: 0.85786802\n",
      "\n",
      "Epoch 86/300\n",
      "--------------------\n",
      "train Loss: 0.40907608 Acc: 0.97177700\n",
      "val Loss: 0.74300770 Acc: 0.85786802\n",
      "\n",
      "Epoch 87/300\n",
      "--------------------\n",
      "train Loss: 0.40859414 Acc: 0.97038328\n",
      "val Loss: 0.74401240 Acc: 0.85279188\n",
      "\n",
      "Epoch 88/300\n",
      "--------------------\n",
      "train Loss: 0.41659167 Acc: 0.96585366\n",
      "val Loss: 0.74176683 Acc: 0.85279188\n",
      "\n",
      "Epoch 89/300\n",
      "--------------------\n",
      "train Loss: 0.40636962 Acc: 0.97142857\n",
      "val Loss: 0.74123829 Acc: 0.85025381\n",
      "\n",
      "Epoch 90/300\n",
      "--------------------\n",
      "train Loss: 0.41359146 Acc: 0.96968641\n",
      "val Loss: 0.77062151 Acc: 0.84010152\n",
      "\n",
      "Epoch 91/300\n",
      "--------------------\n",
      "train Loss: 0.40508187 Acc: 0.97386760\n",
      "val Loss: 0.75870210 Acc: 0.84263959\n",
      "\n",
      "Epoch 92/300\n",
      "--------------------\n",
      "train Loss: 0.41474315 Acc: 0.96411150\n",
      "val Loss: 0.76225663 Acc: 0.85025381\n",
      "\n",
      "Epoch 93/300\n",
      "--------------------\n",
      "train Loss: 0.41262368 Acc: 0.97003484\n",
      "val Loss: 0.75117283 Acc: 0.86040609\n",
      "\n",
      "Epoch 94/300\n",
      "--------------------\n",
      "train Loss: 0.40755284 Acc: 0.97247387\n",
      "val Loss: 0.75361821 Acc: 0.84517766\n",
      "\n",
      "Epoch 95/300\n",
      "--------------------\n",
      "train Loss: 0.40494398 Acc: 0.97491289\n",
      "val Loss: 0.74651039 Acc: 0.85025381\n",
      "\n",
      "Epoch 96/300\n",
      "--------------------\n",
      "train Loss: 0.40498891 Acc: 0.97247387\n",
      "val Loss: 0.75933120 Acc: 0.84263959\n",
      "\n",
      "Epoch 97/300\n",
      "--------------------\n",
      "train Loss: 0.41057344 Acc: 0.97003484\n",
      "val Loss: 0.72568852 Acc: 0.85786802\n",
      "\n",
      "Epoch 98/300\n",
      "--------------------\n",
      "train Loss: 0.40666989 Acc: 0.97247387\n",
      "val Loss: 0.74591490 Acc: 0.84517766\n",
      "\n",
      "Epoch 99/300\n",
      "--------------------\n",
      "train Loss: 0.40916159 Acc: 0.97108014\n",
      "val Loss: 0.72450217 Acc: 0.85786802\n",
      "\n",
      "Epoch 100/300\n",
      "--------------------\n",
      "train Loss: 0.40076156 Acc: 0.97560976\n",
      "val Loss: 0.72953181 Acc: 0.85025381\n",
      "\n",
      "Epoch 101/300\n",
      "--------------------\n",
      "train Loss: 0.39981452 Acc: 0.97595819\n",
      "val Loss: 0.73715254 Acc: 0.85279188\n",
      "\n",
      "Epoch 102/300\n",
      "--------------------\n",
      "train Loss: 0.40104605 Acc: 0.97595819\n",
      "val Loss: 0.74632621 Acc: 0.84517766\n",
      "\n",
      "Epoch 103/300\n",
      "--------------------\n",
      "train Loss: 0.40542237 Acc: 0.97142857\n",
      "val Loss: 0.73307475 Acc: 0.84517766\n",
      "\n",
      "Epoch 104/300\n",
      "--------------------\n",
      "train Loss: 0.41016472 Acc: 0.97038328\n",
      "val Loss: 0.73127879 Acc: 0.84517766\n",
      "\n",
      "Epoch 105/300\n",
      "--------------------\n",
      "train Loss: 0.40396888 Acc: 0.97317073\n",
      "val Loss: 0.74318020 Acc: 0.84263959\n",
      "\n",
      "Epoch 106/300\n",
      "--------------------\n",
      "train Loss: 0.40928484 Acc: 0.97038328\n",
      "val Loss: 0.73871459 Acc: 0.84263959\n",
      "\n",
      "Epoch 107/300\n",
      "--------------------\n",
      "train Loss: 0.39955929 Acc: 0.97909408\n",
      "val Loss: 0.74687118 Acc: 0.84263959\n",
      "\n",
      "Epoch 108/300\n",
      "--------------------\n",
      "train Loss: 0.40451033 Acc: 0.97212544\n",
      "val Loss: 0.74765764 Acc: 0.84263959\n",
      "\n",
      "Epoch 109/300\n",
      "--------------------\n",
      "train Loss: 0.41128959 Acc: 0.96933798\n",
      "val Loss: 0.76823201 Acc: 0.84263959\n",
      "\n",
      "Epoch 110/300\n",
      "--------------------\n",
      "train Loss: 0.40941048 Acc: 0.97247387\n",
      "val Loss: 0.74107483 Acc: 0.84263959\n",
      "\n",
      "Epoch 111/300\n",
      "--------------------\n",
      "train Loss: 0.40323405 Acc: 0.97456446\n",
      "val Loss: 0.75495655 Acc: 0.84263959\n",
      "\n",
      "Epoch 112/300\n",
      "--------------------\n",
      "train Loss: 0.40880959 Acc: 0.96829268\n",
      "val Loss: 0.74489800 Acc: 0.84263959\n",
      "\n",
      "Epoch 113/300\n",
      "--------------------\n",
      "train Loss: 0.39427245 Acc: 0.97944251\n",
      "val Loss: 0.74392122 Acc: 0.84263959\n",
      "\n",
      "Epoch 114/300\n",
      "--------------------\n",
      "train Loss: 0.39636758 Acc: 0.97665505\n",
      "val Loss: 0.75049006 Acc: 0.84263959\n",
      "\n",
      "Epoch 115/300\n",
      "--------------------\n",
      "train Loss: 0.40289220 Acc: 0.96933798\n",
      "val Loss: 0.74881588 Acc: 0.84263959\n",
      "\n",
      "Epoch 116/300\n",
      "--------------------\n",
      "train Loss: 0.40922481 Acc: 0.97456446\n",
      "val Loss: 0.75254966 Acc: 0.84263959\n",
      "\n",
      "Epoch 117/300\n",
      "--------------------\n",
      "train Loss: 0.40221643 Acc: 0.97351916\n",
      "val Loss: 0.75739597 Acc: 0.84263959\n",
      "\n",
      "Epoch 118/300\n",
      "--------------------\n",
      "train Loss: 0.39371079 Acc: 0.97944251\n",
      "val Loss: 0.73902633 Acc: 0.84517766\n",
      "\n",
      "Epoch 119/300\n",
      "--------------------\n",
      "train Loss: 0.40370486 Acc: 0.97386760\n",
      "val Loss: 0.74802745 Acc: 0.84263959\n",
      "\n",
      "Epoch 120/300\n",
      "--------------------\n",
      "train Loss: 0.40650206 Acc: 0.97108014\n",
      "val Loss: 0.76380232 Acc: 0.84263959\n",
      "\n",
      "Epoch 121/300\n",
      "--------------------\n",
      "train Loss: 0.40380084 Acc: 0.97212544\n",
      "val Loss: 0.75287916 Acc: 0.84263959\n",
      "\n",
      "Epoch 122/300\n",
      "--------------------\n",
      "train Loss: 0.41215803 Acc: 0.96585366\n",
      "val Loss: 0.75609041 Acc: 0.84263959\n",
      "\n",
      "Epoch 123/300\n",
      "--------------------\n",
      "train Loss: 0.40564699 Acc: 0.96968641\n",
      "val Loss: 0.75132988 Acc: 0.84263959\n",
      "\n",
      "Epoch 124/300\n",
      "--------------------\n",
      "train Loss: 0.40090712 Acc: 0.97421603\n",
      "val Loss: 0.74706326 Acc: 0.84517766\n",
      "\n",
      "Epoch 125/300\n",
      "--------------------\n",
      "train Loss: 0.40256565 Acc: 0.97700348\n",
      "val Loss: 0.74267610 Acc: 0.84517766\n",
      "\n",
      "Epoch 126/300\n",
      "--------------------\n",
      "train Loss: 0.41634537 Acc: 0.96515679\n",
      "val Loss: 0.74145975 Acc: 0.84517766\n",
      "\n",
      "Epoch 127/300\n",
      "--------------------\n",
      "train Loss: 0.40469982 Acc: 0.97282230\n",
      "val Loss: 0.75278142 Acc: 0.84263959\n",
      "\n",
      "Epoch 128/300\n",
      "--------------------\n",
      "train Loss: 0.40244130 Acc: 0.97247387\n",
      "val Loss: 0.75719665 Acc: 0.84263959\n",
      "\n",
      "Epoch 129/300\n",
      "--------------------\n",
      "train Loss: 0.40313329 Acc: 0.97630662\n",
      "val Loss: 0.75300915 Acc: 0.84263959\n",
      "\n",
      "Epoch 130/300\n",
      "--------------------\n",
      "train Loss: 0.40369024 Acc: 0.97526132\n",
      "val Loss: 0.74973791 Acc: 0.84263959\n",
      "\n",
      "Epoch 131/300\n",
      "--------------------\n",
      "train Loss: 0.41199547 Acc: 0.96585366\n",
      "val Loss: 0.74191673 Acc: 0.84263959\n",
      "\n",
      "Epoch 132/300\n",
      "--------------------\n",
      "train Loss: 0.40046060 Acc: 0.97491289\n",
      "val Loss: 0.74948985 Acc: 0.84263959\n",
      "\n",
      "Epoch 133/300\n",
      "--------------------\n",
      "train Loss: 0.39744091 Acc: 0.97804878\n",
      "val Loss: 0.75770802 Acc: 0.84263959\n",
      "\n",
      "Epoch 134/300\n",
      "--------------------\n",
      "train Loss: 0.40224196 Acc: 0.97317073\n",
      "val Loss: 0.74508033 Acc: 0.84263959\n",
      "\n",
      "Epoch 135/300\n",
      "--------------------\n",
      "train Loss: 0.40420449 Acc: 0.97212544\n",
      "val Loss: 0.76987769 Acc: 0.84263959\n",
      "\n",
      "Epoch 136/300\n",
      "--------------------\n",
      "train Loss: 0.40770570 Acc: 0.97177700\n",
      "val Loss: 0.74876810 Acc: 0.84517766\n",
      "\n",
      "Epoch 137/300\n",
      "--------------------\n",
      "train Loss: 0.40043709 Acc: 0.97526132\n",
      "val Loss: 0.75306465 Acc: 0.84263959\n",
      "\n",
      "Epoch 138/300\n",
      "--------------------\n",
      "train Loss: 0.40024679 Acc: 0.97560976\n",
      "val Loss: 0.74483396 Acc: 0.84263959\n",
      "\n",
      "Epoch 139/300\n",
      "--------------------\n",
      "train Loss: 0.40113429 Acc: 0.97595819\n",
      "val Loss: 0.75275326 Acc: 0.84263959\n",
      "\n",
      "Epoch 140/300\n",
      "--------------------\n",
      "train Loss: 0.41189863 Acc: 0.96968641\n",
      "val Loss: 0.74696247 Acc: 0.84517766\n",
      "\n",
      "Epoch 141/300\n",
      "--------------------\n",
      "train Loss: 0.40408249 Acc: 0.97421603\n",
      "val Loss: 0.74812344 Acc: 0.84517766\n",
      "\n",
      "Epoch 142/300\n",
      "--------------------\n",
      "train Loss: 0.39415051 Acc: 0.97735192\n",
      "val Loss: 0.73482271 Acc: 0.84517766\n",
      "\n",
      "Epoch 143/300\n",
      "--------------------\n",
      "train Loss: 0.40325190 Acc: 0.97317073\n",
      "val Loss: 0.75644791 Acc: 0.84517766\n",
      "\n",
      "Epoch 144/300\n",
      "--------------------\n",
      "train Loss: 0.40313440 Acc: 0.97770035\n",
      "val Loss: 0.74798757 Acc: 0.84517766\n",
      "\n",
      "Epoch 145/300\n",
      "--------------------\n",
      "train Loss: 0.39936030 Acc: 0.97595819\n",
      "val Loss: 0.73185033 Acc: 0.84517766\n",
      "\n",
      "Epoch 146/300\n",
      "--------------------\n",
      "train Loss: 0.39799953 Acc: 0.97386760\n",
      "val Loss: 0.73818926 Acc: 0.84517766\n",
      "\n",
      "Epoch 147/300\n",
      "--------------------\n",
      "train Loss: 0.40364861 Acc: 0.97247387\n",
      "val Loss: 0.74266221 Acc: 0.84517766\n",
      "\n",
      "Epoch 148/300\n",
      "--------------------\n",
      "train Loss: 0.40630591 Acc: 0.97177700\n",
      "val Loss: 0.74243656 Acc: 0.84517766\n",
      "\n",
      "Epoch 149/300\n",
      "--------------------\n",
      "train Loss: 0.40126704 Acc: 0.97247387\n",
      "val Loss: 0.75415949 Acc: 0.84263959\n",
      "\n",
      "Epoch 150/300\n",
      "--------------------\n",
      "train Loss: 0.39729626 Acc: 0.97804878\n",
      "val Loss: 0.73547044 Acc: 0.84517766\n",
      "\n",
      "Epoch 151/300\n",
      "--------------------\n",
      "train Loss: 0.40193698 Acc: 0.97560976\n",
      "val Loss: 0.74948283 Acc: 0.84517766\n",
      "\n",
      "Epoch 152/300\n",
      "--------------------\n",
      "train Loss: 0.39941811 Acc: 0.97874564\n",
      "val Loss: 0.73269870 Acc: 0.85279188\n",
      "\n",
      "Epoch 153/300\n",
      "--------------------\n",
      "train Loss: 0.40687962 Acc: 0.96968641\n",
      "val Loss: 0.74812717 Acc: 0.84263959\n",
      "\n",
      "Epoch 154/300\n",
      "--------------------\n",
      "train Loss: 0.39924486 Acc: 0.97595819\n",
      "val Loss: 0.75235899 Acc: 0.84263959\n",
      "\n",
      "Epoch 155/300\n",
      "--------------------\n",
      "train Loss: 0.39438013 Acc: 0.97770035\n",
      "val Loss: 0.74494623 Acc: 0.84263959\n",
      "\n",
      "Epoch 156/300\n",
      "--------------------\n",
      "train Loss: 0.40481182 Acc: 0.97108014\n",
      "val Loss: 0.75155656 Acc: 0.84517766\n",
      "\n",
      "Epoch 157/300\n",
      "--------------------\n",
      "train Loss: 0.40329746 Acc: 0.97421603\n",
      "val Loss: 0.73828199 Acc: 0.84517766\n",
      "\n",
      "Epoch 158/300\n",
      "--------------------\n",
      "train Loss: 0.40415878 Acc: 0.97456446\n",
      "val Loss: 0.74645362 Acc: 0.84517766\n",
      "\n",
      "Epoch 159/300\n",
      "--------------------\n",
      "train Loss: 0.40011319 Acc: 0.97491289\n",
      "val Loss: 0.75416870 Acc: 0.84263959\n",
      "\n",
      "Epoch 160/300\n",
      "--------------------\n",
      "train Loss: 0.39883057 Acc: 0.97456446\n",
      "val Loss: 0.74289167 Acc: 0.84517766\n",
      "\n",
      "Epoch 161/300\n",
      "--------------------\n",
      "train Loss: 0.39889145 Acc: 0.97491289\n",
      "val Loss: 0.75350676 Acc: 0.84263959\n",
      "\n",
      "Epoch 162/300\n",
      "--------------------\n",
      "train Loss: 0.39898317 Acc: 0.97630662\n",
      "val Loss: 0.75040332 Acc: 0.84517766\n",
      "\n",
      "Epoch 163/300\n",
      "--------------------\n",
      "train Loss: 0.40932940 Acc: 0.97003484\n",
      "val Loss: 0.76675559 Acc: 0.84263959\n",
      "\n",
      "Epoch 164/300\n",
      "--------------------\n",
      "train Loss: 0.40077837 Acc: 0.97665505\n",
      "val Loss: 0.76056289 Acc: 0.84263959\n",
      "\n",
      "Epoch 165/300\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "CHECK_POINT_PATH = '/home/linh/Downloads/Brain/weights/TResNet_Medium.pth'\n",
    "try:\n",
    "    checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "    print(\"checkpoint loaded\")\n",
    "except:\n",
    "    checkpoint = None\n",
    "    print(\"checkpoint not found\")\n",
    "if checkpoint == None:\n",
    "    CHECK_POINT_PATH = CHECK_POINT_PATH\n",
    "model, best_val_loss, best_val_acc = train_model(model,\n",
    "                                                 criterion,\n",
    "                                                 optimizer,\n",
    "                                                 scheduler,\n",
    "                                                 num_epochs = 300,\n",
    "                                                 checkpoint = None #torch.load(CHECK_POINT_PATH)\n",
    "                                                 ) \n",
    "                                                \n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, CHECK_POINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19_EfficientNet_B0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
